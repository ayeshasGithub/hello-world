{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Read_plc_tags.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0tQHoNp/9eiRCXue6agNQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayeshasGithub/hello-world/blob/master/Read_plc_tags.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaKfyv1AydXN",
        "colab_type": "text"
      },
      "source": [
        "# Install Kafka depedencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QehUuM8q1ZR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plc program update July21\n",
        "\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'#'magna_simulation'# magnaPlcTagData\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.Data.LaneID':'line','root.Data.ZoneID':'zone','root.Data.TagID':'tag_name','root.Data.StationID':'station',\n",
        "                \n",
        "                        'root.Data.EquipmentID':'asset','root.Data.TagValue':'tag_value','root.Data.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "#plc_tag_hash={}#dic of dic\n",
        "plc_tag_msg={}\n",
        "\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='latest',\n",
        "                         session_timeout_ms=10000, \n",
        "                          enable_auto_commit=False, auto_commit_interval_ms=5000,\n",
        "                         reconnect_backoff_ms=30000, reconnect_backoff_max_ms=60000,\n",
        "                         max_poll_records=50, max_poll_interval_ms=300000,                        \n",
        "                         group_id='plc_group_a', value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
        "\n",
        "\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    #if msg_count<= 30000:\n",
        "    #    continue\n",
        "    msg = msg.value\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    \n",
        "    len_value=len(new_dic['VALUES'])\n",
        "    print('number of tags in this batch',len_value)#CHANGE 1\n",
        "    \n",
        "    for i in range(len_value):\n",
        "        \n",
        "        value_list=new_dic['VALUES'][i]#type(new_dic['Values'])=list of list\\n\",\n",
        "        #value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "        #print(name_list)\n",
        "        #print(value_list) \n",
        "        #make one dic from one parsed msg => tag\n",
        "        plc_dic={}\n",
        "        for name,value in zip(name_list,value_list):\n",
        "            #print(name,':',value)\n",
        "            if value is None:\n",
        "                value=str(-1)\n",
        "            plc_dic[key_conversion[name]]=str(value).lower()\n",
        "        \n",
        "        #print(plc_dic)#CHANGE 2\n",
        "    \n",
        "        #make primary key for the tag\n",
        "        pk_tag=plc_dic['line']+'.'+plc_dic['zone']+'.'+plc_dic['station']+'.'+plc_dic['asset']+'.'+plc_dic['tag_name']\n",
        "        pk_tag=pk_tag.replace('.-1','')\n",
        "        #print(pk_tag)\n",
        "    \n",
        "        #plc_tag_msg[pk_tag]=plc_dic#COMMENT\n",
        "    \n",
        "    \n",
        "        #redis write    \n",
        "        #r_val=json.dumps(plc_tag_msg)#COMMENT\n",
        "        #r.set('plc_tag_hash',r_val)#UNCOMMENT\n",
        "        #r.hset('plc_tag_experiment',pk_tag,json.dumps(plc_dic))#UNCOMMENT\n",
        "        #r.hset('plc_tag_hash_simu',pk_tag,json.dumps(plc_dic))#UNCOMMENT\n",
        "        r.hset('plc_tag_hash_real',pk_tag,json.dumps(plc_dic))#UNCOMMENT\n",
        "    \n",
        "        #redis read\n",
        "        '''\n",
        "        r_had=r.get('plc_tag_hash')\n",
        "        plc_tag=json.loads(r_had)\n",
        "        #print('from redis read: ',plc_tag)\n",
        "        #'''    \n",
        "    \n",
        "    \n",
        "    \n",
        "        #print(plc_dic)\n",
        "        #print('tag_name: ',plc_dic['tag_name'])\n",
        "        #print('tag_value: ',plc_dic['tag_value'])\n",
        "    \n",
        "    if msg_count%100==0:\n",
        "        #pass\n",
        "        print(msg_count,end=' ')\n",
        "    '''\n",
        "    if msg_count==1:#0001:\n",
        "        print('done')\n",
        "        break\n",
        "    #'''\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLu3IwqZZpW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new 3\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.LaneID':'line','root.ZoneID':'zone','root.TagID':'tag_name','root.StationID':'station',\n",
        "                \n",
        "                        'root.EquipmentID':'asset','root.TagValue':'tag_value','root.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "#plc_tag_hash={}#dic of dic\n",
        "plc_tag_msg={}\n",
        "\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                         session_timeout_ms=10000, \n",
        "                          enable_auto_commit=False, auto_commit_interval_ms=5000,\n",
        "                         reconnect_backoff_ms=30000, reconnect_backoff_max_ms=60000,\n",
        "                         max_poll_records=50, max_poll_interval_ms=300000,                        \n",
        "                         group_id=None, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "\n",
        "\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    #if msg_count<= 30000:\n",
        "    #    continue\n",
        "    msg = msg.value\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    \n",
        "    len_value=len(new_dic['VALUES'])\n",
        "    print('number of values',len_value)\n",
        "    \n",
        "    for i in range(len_value):\n",
        "        \n",
        "        value_list=new_dic['VALUES'][i]#type(new_dic['Values'])=list of list\\n\",\n",
        "        #value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "    \n",
        "         \n",
        "        #make one dic from one parsed msg => tag\n",
        "        plc_dic={}\n",
        "        for name,value in zip(name_list,value_list):\n",
        "            #print(name,':',value)\n",
        "            if value is None:\n",
        "                value=str(-1)\n",
        "            plc_dic[key_conversion[name]]=str(value).lower()\n",
        "        \n",
        "        #print(plc_dic)\n",
        "    \n",
        "        #make primary key for the tag\n",
        "        pk_tag=plc_dic['line']+'.'+plc_dic['zone']+'.'+plc_dic['station']+'.'+plc_dic['asset']+'.'+plc_dic['tag_name']\n",
        "        pk_tag=pk_tag.replace('.-1','')\n",
        "        #print(pk_tag)\n",
        "    \n",
        "        plc_tag_msg[pk_tag]=plc_dic\n",
        "    \n",
        "    \n",
        "        #redis write    \n",
        "        r_val=json.dumps(plc_tag_msg)\n",
        "        #r.set('plc_tag_hash',r_val)#UNCOMMENT\n",
        "        #r.hset('plc_tag_experiment',pk_tag,json.dumps(plc_dic))#UNCOMMENT\n",
        "    \n",
        "        #redis read\n",
        "        '''\n",
        "        r_had=r.get('plc_tag_hash')\n",
        "        plc_tag=json.loads(r_had)\n",
        "        #print('from redis read: ',plc_tag)\n",
        "        #'''    \n",
        "    \n",
        "    \n",
        "    \n",
        "        #print(plc_dic)\n",
        "        print('tag_name: ',plc_dic['tag_name'])\n",
        "        #print('tag_value: ',plc_dic['tag_value'])\n",
        "    \n",
        "    if msg_count%500==0:\n",
        "        print(msg_count,end=' ')\n",
        "    if msg_count==3:#0001:\n",
        "        print('done')\n",
        "        break\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmppjkBNbOZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new 4\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magna_simulation'#'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.Data.LaneID':'line','root.Data.ZoneID':'zone','root.Data.TagID':'tag_name','root.Data.StationID':'station',\n",
        "                \n",
        "                        'root.Data.EquipmentID':'asset','root.Data.TagValue':'tag_value','root.Data.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "#plc_tag_hash={}#dic of dic\n",
        "plc_tag_msg={}\n",
        "\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='latest',\n",
        "                         session_timeout_ms=10000, \n",
        "                          enable_auto_commit=False, auto_commit_interval_ms=5000,\n",
        "                         reconnect_backoff_ms=30000, reconnect_backoff_max_ms=60000,\n",
        "                         max_poll_records=50, max_poll_interval_ms=300000,                        \n",
        "                         group_id='plc_group_a', value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "\n",
        "\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    #if msg_count<= 30000:\n",
        "    #    continue\n",
        "    msg = msg.value\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    \n",
        "    len_value=len(new_dic['VALUES'])\n",
        "    print('number of values',len_value)\n",
        "    \n",
        "    for i in range(len_value):\n",
        "        \n",
        "        value_list=new_dic['VALUES'][i]#type(new_dic['Values'])=list of list\\n\",\n",
        "        #value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "        #print(name_list)\n",
        "        #print(value_list) \n",
        "        #make one dic from one parsed msg => tag\n",
        "        plc_dic={}\n",
        "        for name,value in zip(name_list,value_list):\n",
        "            #print(name,':',value)\n",
        "            if value is None:\n",
        "                value=str(-1)\n",
        "            plc_dic[key_conversion[name]]=str(value).lower()\n",
        "        \n",
        "        #print(plc_dic)\n",
        "    \n",
        "        #make primary key for the tag\n",
        "        pk_tag=plc_dic['line']+'.'+plc_dic['zone']+'.'+plc_dic['station']+'.'+plc_dic['asset']+'.'+plc_dic['tag_name']\n",
        "        pk_tag=pk_tag.replace('.-1','')\n",
        "        #print(pk_tag)\n",
        "    \n",
        "        #plc_tag_msg[pk_tag]=plc_dic#COMMENT\n",
        "    \n",
        "    \n",
        "        #redis write    \n",
        "        #r_val=json.dumps(plc_tag_msg)#COMMENT\n",
        "        #r.set('plc_tag_hash',r_val)#UNCOMMENT\n",
        "        #r.hset('plc_tag_experiment',pk_tag,json.dumps(plc_dic))#UNCOMMENT\n",
        "        r.hset('plc_tag_hash_simu',pk_tag,json.dumps(plc_dic))#UNCOMMENT\n",
        "    \n",
        "        #redis read\n",
        "        '''\n",
        "        r_had=r.get('plc_tag_hash')\n",
        "        plc_tag=json.loads(r_had)\n",
        "        #print('from redis read: ',plc_tag)\n",
        "        #'''    \n",
        "    \n",
        "    \n",
        "    \n",
        "        #print(plc_dic)\n",
        "        print('tag_name: ',plc_dic['tag_name'])\n",
        "        #print('tag_value: ',plc_dic['tag_value'])\n",
        "    \n",
        "    if msg_count%500==0:\n",
        "        print(msg_count,end=' ')\n",
        "    if msg_count==3:#0001:\n",
        "        print('done')\n",
        "        break\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYCFbS62doHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#redis read for Gema, convert byte string\n",
        "    \n",
        "#r_had=r.get('plc_tag_hash')\n",
        "r_had=r.hgetall('plc_tag_hash_simu')\n",
        "#r_had=json.loads(r_had)\n",
        "#plc_tag=json.loads(r_had)\n",
        "#print('from redis read: ',len(plc_tag))\n",
        "print(type(r_had))\n",
        "#dic=dict(r_had)#json.loads(r_had)\n",
        "#print(dic)\n",
        "\n",
        "for key,value in r_had.items():\n",
        "    print('key',str(key,\"utf-8\"))\n",
        "    print('value',str(value,\"utf-8\"))\n",
        "#print(dic['rw43.zone02.st100.100sr1.cycletimetimeracc'])\n",
        "#print(r_had['rw43.plc02.st060.equip001.rw43.plc02.st060.equip001.lsrst'])\n",
        "    #'''    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPPf05WjtPzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#redis experiment\n",
        "\n",
        "#initialize dic\n",
        "new_dic={}\n",
        "\n",
        "new_dic[0]='we'\n",
        "new_dic['1']='he'\n",
        "\n",
        "print(new_dic)\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.StrictRedis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "#'''\n",
        "\n",
        "\n",
        "key='any'\n",
        "#redis write    \n",
        "#r_val=json.dumps(plc_tag_msg)\n",
        "r.hset('plc_tag_experiment',key,json.dumps(new_dic))#UNCOMMENT\n",
        "    \n",
        "#redis read\n",
        "r_haddy=r.hgetall('plc_tag_experiment')\n",
        "print('from redis read: ',r_haddy)\n",
        "#'''    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otEPAL3_tS4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Experiment kafka\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "msg_count=0\n",
        "\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='latest',\n",
        "                         session_timeout_ms=10000, \n",
        "                          enable_auto_commit=False, auto_commit_interval_ms=5000,\n",
        "                         reconnect_backoff_ms=30000, reconnect_backoff_max_ms=60000,\n",
        "                         max_poll_records=50, max_poll_interval_ms=300000,\n",
        "                         \n",
        "                         group_id=None, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    msg = msg.value\n",
        "    \n",
        "    if msg_count==5:\n",
        "        print(msg_count)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQeJvjLtVDa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Redis\n",
        "import the Redis client\n",
        "import redis\n",
        "\n",
        "\n",
        "# Create a redis client\n",
        "redisClient = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
        "\n",
        "# Add key value pairs to the Redis hash\n",
        "hashName = \"Dessert\"\n",
        "redisClient.hset(hashName, 'line', \"Cheesecake\")\n",
        "redisClient.hset(hashName, 'zone', \"zone01\")\n",
        "redisClient.hset(hashName, 'station', \"-1\")\n",
        "redisClient.hset(hashName, 'asset', \"-1\")\n",
        "redisClient.hset(hashName, 'tag_name', \"Zone01_Shift_1\")\n",
        "redisClient.hset(hashName, 'tag_value', \"1\")\n",
        "\n",
        "# Print the hash\n",
        "print(redisClient.hgetall(hashName))pl\n",
        "\n",
        "# Remove a key\n",
        "redisClient.hdel(hashName, 1)\n",
        " \n",
        "\n",
        "# Print the hash after removing a key\n",
        "print(redisClient.hgetall(hashName))\n",
        "\n",
        "{'line': 'rw43',\n",
        " 'zone': 'zone01',\n",
        " 'station': '-1',\n",
        " 'asset': '-1',\n",
        " 'tag_name': 'Zone01_Shift_1',\n",
        " 'tag_value': '1'\n",
        "} \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djyB8j_2QxpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "5563840b-16f7-45f6-c2b0-6060d4ce39a1"
      },
      "source": [
        "#new 1\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.LaneID':'line','root.ZoneID':'zone','root.TagID':'tag_name','root.StationID':'station',\n",
        "                \n",
        "                        'root.EquipmentID':'asset','root.TagValue':'tag_value','root.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "plc_tag_hash={}#dic of dic\n",
        "plc_tag_msg={}\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                          enable_auto_commit=True, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    msg = msg.value\n",
        "    \n",
        "    #print('\\n')\n",
        "    sys.stdout.write('%d'%msg_count)\n",
        "    #print(msg_count)\n",
        "    sys.stdout.flush()\n",
        "    #time.sleep(0.1)\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "  \n",
        "    #make one dic from one parsed msg => tag\n",
        "    plc_dic={}\n",
        "    for name,value in zip(name_list,value_list):\n",
        "        #print(name,':',value)\n",
        "        if value is None:\n",
        "            value=str(-1)\n",
        "        plc_dic[key_conversion[name]]=str(value).lower()\n",
        "        \n",
        "    #print(plc_dic)\n",
        "    \n",
        "    #make primary key for the tag\n",
        "    pk_tag=plc_dic['line']+'.'+plc_dic['zone']+'.'+plc_dic['station']+'.'+plc_dic['asset']+'.'+plc_dic['tag_name']\n",
        "    pk_tag=pk_tag.replace('.-1','')\n",
        "    #print(pk_tag)\n",
        "    \n",
        "    plc_tag_msg[pk_tag]=plc_dic\n",
        "    \n",
        "    \n",
        "    #redis write    \n",
        "    r_val=json.dumps(plc_tag_msg)\n",
        "    r.set('plc_tag_hash',r_val)\n",
        "    \n",
        "    #redis read\n",
        "    r_had=r.get('plc_tag_hash')\n",
        "    plc_tag=json.loads(r_had)\n",
        "    #print('from redis read: ',plc_tag)\n",
        "    #'''    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #print(plc_dic)\n",
        "    #print('tag_name: ',plc_dic['tag_name'])\n",
        "    #print('tag_value: ',plc_dic['tag_value'])\n",
        "    \n",
        "    \n",
        "    if msg_count%100==0:\n",
        "        print(msg_count,end=' ')\n",
        "    if msg_count==30000:\n",
        "        print('done')\n",
        "        break\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8b831f102886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#new 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKafkaConsumer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mredis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kafka'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Day-fGR9_SLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "10619a3e-221b-4d3a-d4ec-9213e982a091"
      },
      "source": [
        "#new\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.LaneID':'line','root.ZoneID':'zone','root.TagID':'tag_name','root.StationID':'station',\n",
        "                        'root.EquipmentID':'asset','root.TagValue':'tag_value','root.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                          enable_auto_commit=True, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    msg = msg.value\n",
        "    \n",
        "    print('\\n')\n",
        "    sys.stdout.write('%d'%msg_count)\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "  \n",
        "    #make one dic from one parsed msg => tag\n",
        "    plc_dic={}\n",
        "    for name,value in zip(name_list,value_list):\n",
        "        #print(name,':',value)\n",
        "        plc_dic[key_conversion[name]]=value\n",
        "    \n",
        "    \n",
        "    #read/write one tag/msg on redis\n",
        "    r_val=json.dumps(plc_dic)\n",
        "    r.set('plc_tag_msg',r_val)\n",
        "    r_had=r.get('plc_tag_msg')\n",
        "    plc_tag=json.loads(r_had)\n",
        "    print('from redis read: ',plc_tag)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #print(plc_dic)\n",
        "    print('tag_name: ',plc_dic['tag_name'])\n",
        "    print('tag_value: ',plc_dic['tag_value'])\n",
        "    \n",
        "  \n",
        "    if msg_count==15:\n",
        "        break\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c75f384e214c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKafkaConsumer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mredis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kafka'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLvkouh5oZbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b559d994-ce4a-4f82-ceaa-c0d2d1966ad0"
      },
      "source": [
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                          group_id='communication_module',\n",
        "                          enable_auto_commit=False, \n",
        "                          max_poll_records=2, max_poll_interval_ms= 300000, \n",
        "                          value_deserializer=lambda x: loads(x.decode('utf-8')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-eb5ef6509078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n\u001b[0m\u001b[1;32m      2\u001b[0m                           \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'communication_module'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           \u001b[0menable_auto_commit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mmax_poll_records\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_poll_interval_ms\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m300000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KafkaConsumer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnGqCy2l6P1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "5ea07224-392f-4b22-e2ee-6ae018b24a2b"
      },
      "source": [
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.LaneID':'line','root.ZoneID':'zone','root.TagID':'tag_name','root.StationID':'station',\n",
        "                        'root.EquipmentID':'asset','root.TagValue':'tag_value','root.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                          enable_auto_commit=True, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    msg = msg.value\n",
        "    \n",
        "    print('\\n')\n",
        "    sys.stdout.write('%d'%msg_count)\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "  \n",
        "    #make one dic from one parsed msg => tag\n",
        "    plc_dic={}\n",
        "    for name,value in zip(name_list,value_list):\n",
        "        #print(name,':',value)\n",
        "        plc_dic[key_conversion[name]]=value\n",
        "    \n",
        "    #print(plc_dic)\n",
        "    print('tag_name: ',plc_dic['tag_name'])\n",
        "    print('tag_value: ',plc_dic['tag_value'])\n",
        "  \n",
        "    if msg_count==15:\n",
        "        break\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-51d82474eacb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKafkaConsumer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mredis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kafka'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMIz_c87tUIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8d8745f8-815e-4ddf-fee9-41824850c3c7"
      },
      "source": [
        "import json\n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "    \n",
        "# kafka host (broker)\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.LaneID':'line','root.ZoneID':'zone','root.TagID':'tag_name','root.StationID':'station',\n",
        "                        'root.EquipmentID':'asset','root.TagValue':'tag_value','root.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                           enable_auto_commit=True, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "    \n",
        "for msg in consumer:\n",
        "  msg = msg.value\n",
        "  msg_count=msg_count+1\n",
        "  sys.stdout.write('\\\\r%d'%msg_count) \n",
        "  print('{}'.format(msg))\n",
        "  \n",
        "  #parse tag from msg\n",
        "  dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "  res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "  new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "  name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "  value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "  \n",
        "  #make one dic from one parsed msg => tag\n",
        "  plc_dic={}\n",
        "  for name,value in zip(name_list,value_list):\n",
        "      #print(name,':',value)\\n\",\n",
        "      plc_dic[key_conversion[name]]=value\n",
        "      #print(plc_dic)\\n\",\n",
        "      print(plc_dic['tag_name'])\n",
        "    \n",
        "      if msg_count==1:\n",
        "        first_tag=plc_dic['tag_name']\n",
        "        if plc_dic['tag_name']==first_tag:\n",
        "          print ('tag repeats')\n",
        "          print('this_tag',plc_dic['tag_name'])\n",
        "          print('msg_count',msg_count)\n",
        "          break\n",
        "          sys.stdout.flush()\n",
        "        time.sleep(0.2)\n",
        "        if msg_count==15:\n",
        "            break\\n\",\n",
        "        #break\\n\",\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-f4b4481266c0>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    break\\n\",\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSY3mOyG7c4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new 2\n",
        "import json \n",
        "from kafka import KafkaConsumer\n",
        "import redis\n",
        "import time\n",
        "import sys\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "\n",
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "#key conversion: {'line': 'rw43', 'zone': 'zone01', 'station': '-1', 'asset': '-1', 'tag_name': 'Zone01_Shift_1', \n",
        "#                   'tag_value': '1', 'tag_datetime':'2020-05-28T11:31:05.89'} \n",
        "key_conversion={'root.LaneID':'line','root.ZoneID':'zone','root.TagID':'tag_name','root.StationID':'station',\n",
        "                \n",
        "                        'root.EquipmentID':'asset','root.TagValue':'tag_value','root.TagDateTime':'tag_datetime'}\n",
        "\n",
        "msg_count=0\n",
        "plc_tag_hash={}#dic of dic\n",
        "plc_tag_msg={}\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,auto_offset_reset='earliest',\n",
        "                          enable_auto_commit=True, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "for msg in consumer:\n",
        "    msg_count=msg_count+1\n",
        "    msg = msg.value\n",
        "    \n",
        "    #print('{0}\\r'.format(msg_count)),\n",
        "    #print(msg_count,end=' ',flush=True)\n",
        "    #sys.stdout.write('%d'%msg_count)\n",
        "    #print(msg_count)\n",
        "    #sys.stdout.flush()\n",
        "    #time.sleep(0.1)\n",
        "    \n",
        "    #print('{}'.format(msg))\n",
        "  \n",
        "    #parse tag from msg\n",
        "    dic_msg=msg[0]#type(msg)=list, type(msg[0])=dic\\n\",\n",
        "    res=json.loads(dic_msg['FeedData'])#type(dic_msg['FeedData'])=str, type(dic_msg['FeedData'][0])=type(res)=list\\n\",\n",
        "    new_dic=res[0]#type(new_dic)=dic\\n\",\n",
        "    name_list=new_dic['NAMES']#type(new_dic['NAMES'])=list\\n\",\n",
        "    value_list=new_dic['VALUES'][0]#type(new_dic['Values'])=list of list\\n\",\n",
        "  \n",
        "    #make one dic from one parsed msg => tag\n",
        "    plc_dic={}\n",
        "    for name,value in zip(name_list,value_list):\n",
        "        #print(name,':',value)\n",
        "        if value is None:\n",
        "            value=str(-1)\n",
        "        plc_dic[key_conversion[name]]=str(value).lower()\n",
        "        \n",
        "    #print(plc_dic)\n",
        "    \n",
        "    #make primary key for the tag\n",
        "    pk_tag=plc_dic['line']+'.'+plc_dic['zone']+'.'+plc_dic['station']+'.'+plc_dic['asset']+'.'+plc_dic['tag_name']\n",
        "    pk_tag=pk_tag.replace('.-1','')\n",
        "    #print(pk_tag)\n",
        "    \n",
        "    plc_tag_msg[pk_tag]=plc_dic\n",
        "    \n",
        "    \n",
        "    #redis write    \n",
        "    r_val=json.dumps(plc_tag_msg)\n",
        "    #r.set('plc_tag_hash',r_val)#UNCOMMENT\n",
        "    \n",
        "    #redis read\n",
        "    '''\n",
        "    r_had=r.get('plc_tag_hash')\n",
        "    plc_tag=json.loads(r_had)\n",
        "    #print('from redis read: ',plc_tag)\n",
        "    #'''    \n",
        "    \n",
        "    \n",
        "    \n",
        "    #print(plc_dic)\n",
        "    #print('tag_name: ',plc_dic['tag_name'])\n",
        "    #print('tag_value: ',plc_dic['tag_value'])\n",
        "    \n",
        "    if msg_count%100==0:\n",
        "        print(msg_count,end=' ')\n",
        "    if msg_count==30000:\n",
        "        print('done')\n",
        "        break\n",
        "    #break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65WG9eR8sfgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "45709bff-90a6-4996-ca5a-fb820a1fee1b"
      },
      "source": [
        "from json import loads\n",
        "from kafka import KafkaConsumer\n",
        "\n",
        "topic_name = 'magnaPlcTagData'\n",
        "b_server=['10.0.1.96:9092']\n",
        "\n",
        "consumer = KafkaConsumer(topic_name, bootstrap_servers=b_server,\n",
        "                          enable_auto_commit=True, value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
        "for message in consumer:\n",
        "  message = message.value\n",
        "  print('{}'.format(message))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-814dc74bed5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkafka\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKafkaConsumer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtopic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'magnaPlcTagData'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'10.0.1.96:9092'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kafka'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8eyNqds1tUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5e517b6-33d0-4ebc-d862-7478fc194e24"
      },
      "source": [
        "!pip install kafka-python\n",
        "from time import sleep\n",
        "from json import dumps\n",
        "from kafka import KafkaProducer\n",
        "from kafka import KafkaConsumer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kafka-python in /usr/local/lib/python3.6/dist-packages (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_vVrWdimTI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from json import loads\n",
        "consumer = KafkaConsumer(\n",
        "    'spring_test',\n",
        "     bootstrap_servers=['localhost:9092'],\n",
        "     auto_offset_reset='earliest',\n",
        "     enable_auto_commit=True,\n",
        "     group_id='my-group',\n",
        "     value_deserializer=lambda x: loads(x.decode('utf-8')));\n",
        "\n",
        "for message in consumer:\n",
        "  message = message.value;\n",
        "  print('{}'.format(message))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvjQZiHv8w4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_name = 'magnaPlcTagData'\n",
        "consumer = KafkaConsumer(topic_name, auto_offset_reset='earliest', \n",
        "                         bootstrap_servers=['10.0.1.96:9092'], api_version=(0, 10), consumer_timeout_ms=1000000)\n",
        "for msg in consumer:\n",
        "  print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h01yCZRri4jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kafka import KafkaProducer\n",
        "producer = KafkaProducer(bootstrap_servers='10.0.1.96:9092')\n",
        "producer.send('sample', b'Hello, World!')\n",
        "producer.send('sample', key=b'message-two', value=b'This is Kafka-Python')\n",
        "\n",
        "from kafka import KafkaConsumer\n",
        "consumer = KafkaConsumer('sample')\n",
        "for message in consumer:\n",
        "    print (message)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux3DycvzU_ok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ea3a924-738f-4e50-e919-12d292be603b"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print('Running Consumer..')\n",
        "    parsed_records = []\n",
        "    topic_name = 'raw_recipes'\n",
        "    parsed_topic_name = 'parsed_recipes'\n",
        "\n",
        "    consumer = KafkaConsumer(topic_name, auto_offset_reset='earliest',\n",
        "                             bootstrap_servers=['localhost:9092'], api_version=(0, 10), consumer_timeout_ms=1000)\n",
        "    for msg in consumer:\n",
        "        html = msg.value\n",
        "        result = parse(html)\n",
        "        parsed_records.append(result)\n",
        "    consumer.close()\n",
        "    sleep(5)\n",
        "\n",
        "    if len(parsed_records) > 0:\n",
        "        print('Publishing records..')\n",
        "        producer = connect_kafka_producer()\n",
        "        for rec in parsed_records:\n",
        "            publish_message(producer, parsed_topic_name, 'parsed', rec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Consumer..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C73eUXVeVekp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d88d969f-14b1-4d9a-ea65-12eebedd02e8"
      },
      "source": [
        "#IP: 10.0.1.96\n",
        "#Port: 9092\n",
        "#Topic name: magnaPlcTagData\n",
        "from time import sleep\n",
        "from json import dumps\n",
        "from kafka import KafkaProducer\n",
        "from kafka import KafkaConsumer\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('Running Consumer..')\n",
        "    parsed_records = []\n",
        "    topic_name = 'magnaPlcTagData'\n",
        "    parsed_topic_name = 'parsed_recipes'\n",
        "\n",
        "    #consumer = KafkaConsumer(topic_name, auto_offset_reset='earliest', bootstrap_servers=['localhost:9092'], api_version=(0, 10), consumer_timeout_ms=1000)\n",
        "    consumer = KafkaConsumer(topic_name, auto_offset_reset='earliest', bootstrap_servers=['10.0.1.96:9092'], api_version=(0, 10), consumer_timeout_ms=1000)\n",
        "    for msg in consumer:\n",
        "        html = msg.value\n",
        "        result = parse(html)\n",
        "        parsed_records.append(result)\n",
        "    consumer.close()\n",
        "    sleep(5)\n",
        "\n",
        "    if len(parsed_records) > 0:\n",
        "        print('Publishing records..')\n",
        "        producer = connect_kafka_producer()\n",
        "        for rec in parsed_records:\n",
        "            publish_message(producer, parsed_topic_name, 'parsed', rec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Consumer..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj54oYn_4dk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topic_name = 'magnaPlcTagData'\n",
        "consumer = KafkaConsumer(topic_name, auto_offset_reset='earliest', \n",
        "                         bootstrap_servers=['10.0.1.96:9092'], api_version=(0, 10), consumer_timeout_ms=1000)\n",
        "for msg in consumer:\n",
        "  print(msg.key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAwn8aOSH4Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kafka import KafkaConsumer\n",
        "\n",
        "# To consume latest messages and auto-commit offsets\n",
        "consumer = KafkaConsumer('magnaPlcTagData', bootstrap_servers=['10.0.1.96:9092'],api_version=(0, 10, 1))\n",
        "for message in consumer:\n",
        "    # message value and key are raw bytes -- decode if necessary!\n",
        "    # e.g., for unicode: `message.value.decode('utf-8')`\n",
        "    #print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
        "    #                                     message.offset, message.key,\n",
        "    #                                      message.value))\n",
        "    print(msg.key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAs14lXEF4UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pycharm code\n",
        "#import kafka\n",
        "from kafka import KafkaConsumer\n",
        "import pandas\n",
        "topic_name = 'magnaPlcTagData'\n",
        "consumer = KafkaConsumer(topic_name, auto_offset_reset='earliest',\n",
        "                         bootstrap_servers=['10.0.1.96:9092'], api_version=(0, 10), consumer_timeout_ms=10)\n",
        "\n",
        "#consumer = KafkaConsumer(topic_name, bootstrap_servers=['10.0.1.96:9092'])\n",
        "for msg in consumer:\n",
        "  print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtJvdkqEYwUZ",
        "colab_type": "text"
      },
      "source": [
        "# communication_module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Y8-fWMTJSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mqtt pulls from redis keys\n",
        "\n",
        "#!pip3 install paho-mqtt\n",
        "import paho.mqtt.client as mqtt #import the client1\n",
        "broker_address=\"localhost\"#\"192.168.1.184\" \n",
        "#broker_address=\"iot.eclipse.org\" #use external broker\n",
        "client = mqtt.Client(\"P1\") #create new instance\n",
        "client.connect(broker_address) #connect to broker\n",
        "client.publish(\"house/main-light\",\"OFF\")#publish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXN8IWLdaakK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "#url = \"https://plc-iot.c2m.net/api/v1/data/process\"\n",
        "#url = \"https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fhelio-ent.c2m.net%2Flogin.aspx&data=02%7C01%7Cayeshas%40okstate.edu%7Ce33dcfb71016446bad6608d7f6b3bb95%7C2a69c91de8494e34a230cdf8b27e1964%7C0%7C1%7C637249124117860660&sdata=%2F6sf3qNRTsDbmWgWdUDKsS%2FrOy6vJ%2FiHgA1ocMWNMbo%3D&reserved=0\"\n",
        "#url = \"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=XipmK93J5vGOb8hvZ/S8rge856C/TG6ovA7DCelU@/Y=&parameterType=LISTDATA\"\n",
        "url = \"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=XipmK93J5vGOb8hvZ/S8rge856C/TG6ovA7DCelU@/Y=&parameterType=LISTDATA\"\n",
        "#headers = {\"Authorization\": \"CSWQpToX4KLCwODDd3QCmBzak8/DYJ\" }\n",
        "response = requests.get(url)#,headers=headers)\n",
        "print(response.text)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcBlVOwJpodq",
        "colab_type": "text"
      },
      "source": [
        "# Standard API format to request data from helio server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfm23DWXpxJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "token_string = \"\"\n",
        "url=\"\"\n",
        "headers= {\"Authorization\": token_string}\n",
        "response=requests.get(url,headers=headers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AamsxSGOdTUl",
        "colab_type": "text"
      },
      "source": [
        "# Requesting data from PLC feed of helio server\n",
        "\n",
        "feedID= XipmK93J5vGOb8hvZ/S8rge856C/TG6ovA7DCelU@/Y=<br>\n",
        "Given Feed ID: iGfXcckbZrSCd8G4xjek1TV9t@ZbzdAP4lU0/bUeyQQ= "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw15xu97b4DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "url = \"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=XipmK93J5vGOb8hvZ/S8rge856C/TG6ovA7DCelU@/Y=&parameterType=LISTDATA\"\n",
        "\n",
        "#url=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=iGfXcckbZrSCd8G4xjek1TV9t@ZbzdAP4lU0/bUeyQQ=&parameterType=LISTDATA\"\n",
        "#headers = {\"Authorization\": \"CSWQpToX4KLCwODDd3QCmBzak8/DYJ\" }\n",
        "response = requests.get(url)#,headers=headers)\n",
        "print(response.text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ywtfS5-dqTA",
        "colab_type": "text"
      },
      "source": [
        "# Print XML plc tags as string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfa1XLJv0BmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "response_text=ET.fromstring(response.text)#prints wordpad with xd \n",
        "response_xmlstr = ET.tostring(response_text, encoding='utf8', method='xml')#prints 1 line but has all the info\n",
        "xml_str = response_xmlstr.decode()#prints wordpad without xd\n",
        "\n",
        "#print(type(response_text))#<class 'xml.etree.ElementTree.Element'>\n",
        "#print(type(response_xmlstr))# <class 'bytes'>\n",
        "#print(type(xml_str))# <class 'str'>\n",
        "print(xml_str)# <class 'str'>\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YHKShrhcquf",
        "colab_type": "text"
      },
      "source": [
        "# Traversing the xml tree of plc tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78dtXOppBVQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for node in response_text.iter():\n",
        "  print (node.tag, node.attrib, node.text)\n",
        "  #print(node)#Elements, such as <Element 'root.EquipmentID' at 0x7f05be878868>, <Element 'root.TagDateTime' at 0x7f05be878598>,<Element 'Table1' at 0x7f05be8785e8>\n",
        "  #print(node.text)\n",
        "  #if node.text=='RW43.PLC01.Zone1.ST045.Equip018.CycleTime':\n",
        "    #print(node.tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xag_DDoc6DOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install and import redis\n",
        "!pip install redis\n",
        "!pip install t_log\n",
        "import redis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNbLM7V96syw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#how to setup connection with redis, where do I get password?\n",
        "# https://opensource.com/article/18/4/how-build-hello-redis-with-python\n",
        "#next task would be write to redis\n",
        "#then next task would be read back from redis by reconnecting\n",
        "import redis\n",
        "\n",
        "redis_host = \"localhost\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "'''\n",
        "r = pyredis.Redis(host='localhost', port=redis_port, password=redis_password)\n",
        "r.set(\"msg:hello\", \"Hello Redis!!!\")\n",
        "msg = r.get(\"msg:hello\")\n",
        "print(msg)\n",
        "#'''\n",
        "\n",
        "res = redis.Redis(host='47.99.94.49', port=6379, db=0)\n",
        "res.set(\"name\",\"Ayesha\")\n",
        "print(res.get('name'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8ViK87qw26h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install redis-server\n",
        "!redis-cli"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2asU99NheFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install redis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY3JXX3GJ4Ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2dbeac74-3ce5-4c12-bc27-21280c8474f0"
      },
      "source": [
        "import redis\n",
        "\n",
        "# step 2: define our connection information for Redis\n",
        "# Replaces with your configuration information\n",
        "redis_host = \"192.168.2.11\"#\"localhost\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "\n",
        "\n",
        "def hello_redis():\n",
        "    \"\"\"Example Hello Redis Program\"\"\"\n",
        "   \n",
        "    # step 3: create the Redis Connection object\n",
        "    try:\n",
        "   \n",
        "        # The decode_repsonses flag here directs the client to convert the responses from Redis into Python strings\n",
        "        # using the default encoding utf-8.  This is client specific.\n",
        "        r = redis.StrictRedis(host=redis_host, port=redis_port, password=redis_password, decode_responses=True)\n",
        "   \n",
        "        # step 4: Set the hello message in Redis\n",
        "        r.set(\"msg:hello\", \"Hello Redis!!!\")\n",
        "\n",
        "        # step 5: Retrieve the hello message from Redis\n",
        "        msg = r.get(\"msg:hello\")\n",
        "        print(msg)        \n",
        "   \n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "\n",
        "hello_redis()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error 110 connecting to 192.168.2.11:6379. Connection timed out.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPHwuUeui67X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import redis\n",
        "\n",
        "\n",
        "#res = redis.Redis(host='192.168.2.11', port=6379, db=0)\n",
        "#res = redis.Redis(host=\"localhost\", port=6379,db=0)#password=\"\")\n",
        "#r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
        "#r = redis.Redis(host='192.168.2.11', port=6379, decode_responses=True)\n",
        "rC = redis.Redis(host='192.168.2.11', port=6379, db=0)\n",
        "#rC = redis.StrictRedis(host='localhost',port=6379,db=0)\n",
        "rC.set(\"name\",\"Ayesha\")\n",
        "print(rC.get('name'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pMvxwWWu8sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import the Redis client\n",
        "import redis\n",
        "\n",
        "\n",
        "# Create a redis client\n",
        "redisClient = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
        "\n",
        "# Add key value pairs to the Redis hash\n",
        "hashName = \"Dessert\"\n",
        "redisClient.hset(hashName, 'line', \"Cheesecake\")\n",
        "redisClient.hset(hashName, 'zone', \"zone01\")\n",
        "redisClient.hset(hashName, 'station', \"-1\")\n",
        "redisClient.hset(hashName, 'asset', \"-1\")\n",
        "redisClient.hset(hashName, 'tag_name', \"Zone01_Shift_1\")\n",
        "redisClient.hset(hashName, 'tag_value', \"1\")\n",
        "\n",
        "# Print the hash\n",
        "print(redisClient.hgetall(hashName))\n",
        "\n",
        "# Remove a key\n",
        "redisClient.hdel(hashName, 1)\n",
        " \n",
        "\n",
        "# Print the hash after removing a key\n",
        "print(redisClient.hgetall(hashName))\n",
        "\n",
        "{'line': 'rw43',\n",
        " 'zone': 'zone01',\n",
        " 'station': '-1',\n",
        " 'asset': '-1',\n",
        " 'tag_name': 'Zone01_Shift_1',\n",
        " 'tag_value': '1'\n",
        "} \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqqGJhObOzzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import redis\n",
        "\n",
        "r = redis.StrictRedis('localhost')\n",
        "mydict = {1:2,2:3,3:4}\n",
        "p_mydict = pickle.dumps(mydict)\n",
        "r.set('mydict',p_mydict)\n",
        "\n",
        "read_dict = r.get('mydict')\n",
        "yourdict = pickle.loads(read_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQc7XEgYpjPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install redis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpyXCKSOpXLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import redis\n",
        "r = redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "x = r.get(\"analytics_results\")\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgqluccqi_Bm",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "# <font color='blue'> Workflow feeds </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMhmhrIZeRzi",
        "colab_type": "text"
      },
      "source": [
        "# Requesting data from Workflow feed of helio server\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-eHN3dvIIKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#experiment workflow\n",
        "# https://stackoverflow.com/questions/44344077/python-requests-get-from-multiple-pages \n",
        "import grequests  \n",
        "urls = ['http://google.com', 'http://yahoo.com', 'http://bing.com']  \n",
        "unsent_request = (grequests.get(url) for url in urls)\n",
        "\n",
        "results = grequests.map(unsent_request) \n",
        "\n",
        "\n",
        "#https://stackoverflow.com/questions/53773904/python-to-retrieve-multiple-pages-of-data-from-api-with-get \n",
        "# ASK AJAY AND KHURSHEED WHY THERE IS NO PAGE INFO\n",
        "import requests\n",
        "for page in range(1,4458709):\n",
        "    url = 'https://api.safecast.org/en-US/measurements.json?page=%s'%page\n",
        "    data = requests.get(url)\n",
        "    print data.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1182qOr8xri",
        "colab_type": "text"
      },
      "source": [
        "If two lines can have different shifts (and I am assuming so), then schedule should go under that line<br>\n",
        "If not, we can have it as a separate key outside the lines <br>\n",
        "If not, that makes things easier (smile)\n",
        "\n",
        "\n",
        "Under a job, there is shift1, line etc<br>\n",
        "Question is: are other shifts and line are without jobs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjSb5eUseYuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46199d0c-cff0-42e4-ba6c-bc9c4354e41c"
      },
      "source": [
        "!pip install xmltodict\n",
        "import requests\n",
        "#info: data will be overwritten on workflow feed- Ajay confirmed\n",
        "#looks like to read multiple pages one url is not enough\n",
        "#\n",
        "\n",
        "\n",
        "#links for 5 workflow feeds\n",
        "url_mShift = \"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=moU39Gbxtz9IhQO0gUy@EQAKbJcR374vb@IVb6kWwH0=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\"# 3 record\n",
        "url_mJob=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=GIcqmjbvPvCFX3QNIsJbTNa99MyIUuvAFUyKPTBcs9g=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" #has zero records\n",
        "url_mStation=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=GN3jGNVF03thDKOMppdZf/hjLH5vss2SgBlEkNaZvtE=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" #20 records\n",
        "url_mZone=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=LYZEOIUPmsEILn4DoGwhlGw0VaYZ6Yh8@bEKrGOlN6A=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" # 2 records\n",
        "url_mLine=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=XWPuVgYIhUVEZXRsr6gAFq2BPeTCdlLJxRBpvg07WLM=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" # 1 record\n",
        "url_mAsset=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=/y0R6s3pWwReO8a/3ef9tmtO8RAT/U/AKFfmPAD3egA=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\"\n",
        "\n",
        "\n",
        "#get response\n",
        "url=url_mShift\n",
        "response = requests.get(url)#,headers=headers)\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "response_text=ET.fromstring(response.text)#prints wordpad with xd \n",
        "response_xmlstr = ET.tostring(response_text, encoding='utf8', method='xml')#prints 1 line but has all the info\n",
        "xml_str = response_xmlstr.decode()#prints wordpad without xd\n",
        "\n",
        "\n",
        "#print response\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n",
            "<?xml version=\"1.0\" encoding=\"utf-8\"?><root><response status=\"SUCCESS\" startrecord=\"1\" fetchedrecords=\"6\" totalrecords=\"6\"><NewDataSet>&#xD;\n",
            "  <Table1>&#xD;\n",
            "    <c2mdatetime>2020-07-17T14:31:49.329Z</c2mdatetime>&#xD;\n",
            "    <TRNSCTNID>11856</TRNSCTNID>&#xD;\n",
            "    <CRTDON>2020-06-25T03:08:44.000Z</CRTDON>&#xD;\n",
            "    <MODFON>2020-06-29T14:01:11.000Z</MODFON>&#xD;\n",
            "    <CRTDBY>3871</CRTDBY>&#xD;\n",
            "    <MODFBY>3871</MODFBY>&#xD;\n",
            "    <fmsscheduleid>1JTE</fmsscheduleid>&#xD;\n",
            "    <fmsschedulename>Shift 1</fmsschedulename>&#xD;\n",
            "    <fmsschedulelinelink>RW43</fmsschedulelinelink>&#xD;\n",
            "    <fmsscheduledays/>&#xD;\n",
            "    <fmsschedulestarttime>12:00 Am</fmsschedulestarttime>&#xD;\n",
            "    <fmsscheduleendtime>08:00 Am</fmsscheduleendtime>&#xD;\n",
            "    <fmsschedulebreakstart>02:00 Am</fmsschedulebreakstart>&#xD;\n",
            "    <fmsschedulebreakend>02:15 Am</fmsschedulebreakend>&#xD;\n",
            "    <fmsschedulelunchstart>04:00 Am</fmsschedulelunchstart>&#xD;\n",
            "    <fmsschedulelunchend>05:00 Am</fmsschedulelunchend>&#xD;\n",
            "    <fmsscheduledaysnew>Monday!Tuesday!Wednesday!Thursday!Friday</fmsscheduledaysnew>&#xD;\n",
            "    <StageName>Status</StageName>&#xD;\n",
            "    <StateName>Active</StateName>&#xD;\n",
            "    <username>lmv_admin@yopmail.com</username>&#xD;\n",
            "    <companyname>MagnaLMVCompany4</companyname>&#xD;\n",
            "    <groupname>MagnaLMVCompany4</groupname>&#xD;\n",
            "  </Table1>&#xD;\n",
            "  <Table1>&#xD;\n",
            "    <c2mdatetime>2020-07-17T14:31:49.329Z</c2mdatetime>&#xD;\n",
            "    <TRNSCTNID>11857</TRNSCTNID>&#xD;\n",
            "    <CRTDON>2020-06-29T13:58:23.000Z</CRTDON>&#xD;\n",
            "    <MODFON>2020-06-29T13:58:23.000Z</MODFON>&#xD;\n",
            "    <CRTDBY>3871</CRTDBY>&#xD;\n",
            "    <MODFBY>3871</MODFBY>&#xD;\n",
            "    <fmsscheduleid>1QRL</fmsscheduleid>&#xD;\n",
            "    <fmsschedulename>Shift 2</fmsschedulename>&#xD;\n",
            "    <fmsschedulelinelink>RW43</fmsschedulelinelink>&#xD;\n",
            "    <fmsscheduledays/>&#xD;\n",
            "    <fmsschedulestarttime>08:00 Am</fmsschedulestarttime>&#xD;\n",
            "    <fmsscheduleendtime>04:00 Pm</fmsscheduleendtime>&#xD;\n",
            "    <fmsschedulebreakstart>10:00 Am</fmsschedulebreakstart>&#xD;\n",
            "    <fmsschedulebreakend>10:15 Am</fmsschedulebreakend>&#xD;\n",
            "    <fmsschedulelunchstart>12:00 Pm</fmsschedulelunchstart>&#xD;\n",
            "    <fmsschedulelunchend>01:00 Pm</fmsschedulelunchend>&#xD;\n",
            "    <fmsscheduledaysnew>Monday!Tuesday!Wednesday!Thursday!Friday</fmsscheduledaysnew>&#xD;\n",
            "    <StageName>Status</StageName>&#xD;\n",
            "    <StateName>Active</StateName>&#xD;\n",
            "    <username>lmv_admin@yopmail.com</username>&#xD;\n",
            "    <companyname>MagnaLMVCompany4</companyname>&#xD;\n",
            "    <groupname>MagnaLMVCompany4</groupname>&#xD;\n",
            "  </Table1>&#xD;\n",
            "  <Table1>&#xD;\n",
            "    <c2mdatetime>2020-07-17T14:31:49.329Z</c2mdatetime>&#xD;\n",
            "    <TRNSCTNID>11858</TRNSCTNID>&#xD;\n",
            "    <CRTDON>2020-06-29T14:02:33.000Z</CRTDON>&#xD;\n",
            "    <MODFON>2020-06-29T14:02:33.000Z</MODFON>&#xD;\n",
            "    <CRTDBY>3871</CRTDBY>&#xD;\n",
            "    <MODFBY>3871</MODFBY>&#xD;\n",
            "    <fmsscheduleid>15PN</fmsscheduleid>&#xD;\n",
            "    <fmsschedulename>Shift 3</fmsschedulename>&#xD;\n",
            "    <fmsschedulelinelink>RW43</fmsschedulelinelink>&#xD;\n",
            "    <fmsscheduledays/>&#xD;\n",
            "    <fmsschedulestarttime>04:00 Pm</fmsschedulestarttime>&#xD;\n",
            "    <fmsscheduleendtime>12:00 Am</fmsscheduleendtime>&#xD;\n",
            "    <fmsschedulebreakstart>06:00 Am</fmsschedulebreakstart>&#xD;\n",
            "    <fmsschedulebreakend>06:15 Am</fmsschedulebreakend>&#xD;\n",
            "    <fmsschedulelunchstart>08:00 Pm</fmsschedulelunchstart>&#xD;\n",
            "    <fmsschedulelunchend>09:00 Pm</fmsschedulelunchend>&#xD;\n",
            "    <fmsscheduledaysnew>Monday!Tuesday!Wednesday!Thursday!Friday</fmsscheduledaysnew>&#xD;\n",
            "    <StageName>Status</StageName>&#xD;\n",
            "    <StateName>Active</StateName>&#xD;\n",
            "    <username>lmv_admin@yopmail.com</username>&#xD;\n",
            "    <companyname>MagnaLMVCompany4</companyname>&#xD;\n",
            "    <groupname>MagnaLMVCompany4</groupname>&#xD;\n",
            "  </Table1>&#xD;\n",
            "  <Table1>&#xD;\n",
            "    <c2mdatetime>2020-07-17T14:31:49.329Z</c2mdatetime>&#xD;\n",
            "    <TRNSCTNID>11906</TRNSCTNID>&#xD;\n",
            "    <CRTDON>2020-07-01T17:52:17.000Z</CRTDON>&#xD;\n",
            "    <MODFON>2020-07-01T17:52:17.000Z</MODFON>&#xD;\n",
            "    <CRTDBY>3871</CRTDBY>&#xD;\n",
            "    <MODFBY>3871</MODFBY>&#xD;\n",
            "    <fmsscheduleid>17YP</fmsscheduleid>&#xD;\n",
            "    <fmsschedulename>Shift 1</fmsschedulename>&#xD;\n",
            "    <fmsschedulelinelink>RW44</fmsschedulelinelink>&#xD;\n",
            "    <fmsscheduledays/>&#xD;\n",
            "    <fmsschedulestarttime>12:00 Am</fmsschedulestarttime>&#xD;\n",
            "    <fmsscheduleendtime>08:00 Am</fmsscheduleendtime>&#xD;\n",
            "    <fmsschedulebreakstart>02:00 Am</fmsschedulebreakstart>&#xD;\n",
            "    <fmsschedulebreakend>02:15 Am</fmsschedulebreakend>&#xD;\n",
            "    <fmsschedulelunchstart>04:00 Am</fmsschedulelunchstart>&#xD;\n",
            "    <fmsschedulelunchend>05:00 Am</fmsschedulelunchend>&#xD;\n",
            "    <fmsscheduledaysnew>Monday!Tuesday!Wednesday!Thursday!Friday</fmsscheduledaysnew>&#xD;\n",
            "    <StageName>Status</StageName>&#xD;\n",
            "    <StateName>Active</StateName>&#xD;\n",
            "    <username>lmv_admin@yopmail.com</username>&#xD;\n",
            "    <companyname>MagnaLMVCompany4</companyname>&#xD;\n",
            "    <groupname>MagnaLMVCompany4</groupname>&#xD;\n",
            "  </Table1>&#xD;\n",
            "  <Table1>&#xD;\n",
            "    <c2mdatetime>2020-07-17T14:31:49.329Z</c2mdatetime>&#xD;\n",
            "    <TRNSCTNID>11907</TRNSCTNID>&#xD;\n",
            "    <CRTDON>2020-07-01T17:53:18.000Z</CRTDON>&#xD;\n",
            "    <MODFON>2020-07-01T17:53:18.000Z</MODFON>&#xD;\n",
            "    <CRTDBY>3871</CRTDBY>&#xD;\n",
            "    <MODFBY>3871</MODFBY>&#xD;\n",
            "    <fmsscheduleid>1G51</fmsscheduleid>&#xD;\n",
            "    <fmsschedulename>Shift 2</fmsschedulename>&#xD;\n",
            "    <fmsschedulelinelink>RW44</fmsschedulelinelink>&#xD;\n",
            "    <fmsscheduledays/>&#xD;\n",
            "    <fmsschedulestarttime>08:00 Am</fmsschedulestarttime>&#xD;\n",
            "    <fmsscheduleendtime>04:00 Pm</fmsscheduleendtime>&#xD;\n",
            "    <fmsschedulebreakstart>10:00 Am</fmsschedulebreakstart>&#xD;\n",
            "    <fmsschedulebreakend>10:30 Am</fmsschedulebreakend>&#xD;\n",
            "    <fmsschedulelunchstart>12:00 Pm</fmsschedulelunchstart>&#xD;\n",
            "    <fmsschedulelunchend>01:00 Pm</fmsschedulelunchend>&#xD;\n",
            "    <fmsscheduledaysnew>Monday!Tuesday!Wednesday!Thursday!Friday</fmsscheduledaysnew>&#xD;\n",
            "    <StageName>Status</StageName>&#xD;\n",
            "    <StateName>Active</StateName>&#xD;\n",
            "    <username>lmv_admin@yopmail.com</username>&#xD;\n",
            "    <companyname>MagnaLMVCompany4</companyname>&#xD;\n",
            "    <groupname>MagnaLMVCompany4</groupname>&#xD;\n",
            "  </Table1>&#xD;\n",
            "  <Table1>&#xD;\n",
            "    <c2mdatetime>2020-07-17T14:31:49.329Z</c2mdatetime>&#xD;\n",
            "    <TRNSCTNID>11908</TRNSCTNID>&#xD;\n",
            "    <CRTDON>2020-07-01T17:54:14.000Z</CRTDON>&#xD;\n",
            "    <MODFON>2020-07-01T17:54:14.000Z</MODFON>&#xD;\n",
            "    <CRTDBY>3871</CRTDBY>&#xD;\n",
            "    <MODFBY>3871</MODFBY>&#xD;\n",
            "    <fmsscheduleid>1IWJ</fmsscheduleid>&#xD;\n",
            "    <fmsschedulename>Shift 3</fmsschedulename>&#xD;\n",
            "    <fmsschedulelinelink>RW44</fmsschedulelinelink>&#xD;\n",
            "    <fmsscheduledays/>&#xD;\n",
            "    <fmsschedulestarttime>04:00 Pm</fmsschedulestarttime>&#xD;\n",
            "    <fmsscheduleendtime>12:00 Am</fmsscheduleendtime>&#xD;\n",
            "    <fmsschedulebreakstart>06:00 Pm</fmsschedulebreakstart>&#xD;\n",
            "    <fmsschedulebreakend>06:15 Pm</fmsschedulebreakend>&#xD;\n",
            "    <fmsschedulelunchstart>08:00 Pm</fmsschedulelunchstart>&#xD;\n",
            "    <fmsschedulelunchend>09:00 Pm</fmsschedulelunchend>&#xD;\n",
            "    <fmsscheduledaysnew>Monday!Tuesday!Wednesday!Thursday!Friday</fmsscheduledaysnew>&#xD;\n",
            "    <StageName>Status</StageName>&#xD;\n",
            "    <StateName>Active</StateName>&#xD;\n",
            "    <username>lmv_admin@yopmail.com</username>&#xD;\n",
            "    <companyname>MagnaLMVCompany4</companyname>&#xD;\n",
            "    <groupname>MagnaLMVCompany4</groupname>&#xD;\n",
            "  </Table1>&#xD;\n",
            "</NewDataSet></response></root>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDVaOMSEiqSZ",
        "colab_type": "text"
      },
      "source": [
        "# Print workflow feeds as string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIrifb4KivUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "response_text=ET.fromstring(response.text)#prints wordpad with xd \n",
        "response_xmlstr = ET.tostring(response_text, encoding='utf8', method='xml')#prints 1 line but has all the info\n",
        "xml_str = response_xmlstr.decode()#prints wordpad without xd\n",
        "\n",
        "#print(type(response_text))#<class 'xml.etree.ElementTree.Element'>\n",
        "#print(type(response_xmlstr))# <class 'bytes'>\n",
        "#print(type(xml_str))# <class 'str'>\n",
        "print(xml_str)# <class 'str'>\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vHqmZopjUUP",
        "colab_type": "text"
      },
      "source": [
        "# Parse workflow feed which is an xml tree & put in a dic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R34FuebpjZxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "527cb1f2-9f82-4a38-c4ca-1421b9fcf423"
      },
      "source": [
        "count=0\n",
        "for node in response_text.iter():\n",
        "  #print (node.tag, node.attrib, node.text)\n",
        "  \n",
        "  #print(node.tag)#Elements, such as <Element 'root.EquipmentID' at 0x7f05be878868>, <Element 'root.TagDateTime' at 0x7f05be878598>,<Element 'Table1' at 0x7f05be8785e8> KEY\n",
        "  #print(node.tag)\n",
        "  if node.tag=='response':\n",
        "    print(node.text)\n",
        "    dic=node.attrib\n",
        "    print(node.attrib)\n",
        "    print(dic['fetchedrecords'])\n",
        "    print(dic['totalrecords'])\n",
        "    \n",
        "  if node.tag=='Table1':\n",
        "    count=count+1\n",
        "    #print(node.tag)\n",
        "    #print(node.text)\n",
        "print('total',count)\n",
        "  #print(node.text) #should go to dic value? make that sure VALUE\n",
        "  #print(node.text)\n",
        "  #if node.text=='RW43.PLC01.Zone1.ST045.Equip018.CycleTime':\n",
        "    #print(node.tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "{'status': 'SUCCESS', 'startrecord': '1', 'fetchedrecords': '47', 'totalrecords': '47'}\n",
            "47\n",
            "47\n",
            "total 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa_EvV9HxGVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0f7b868-5ecd-40b8-ef45-2e7f447e390a"
      },
      "source": [
        "d={'a':2, 'b':5, 'c':8}\n",
        "\n",
        "d['aa'] = d.pop('a')\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'b': 5, 'c': 8, 'aa': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JifENlkddVC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3059e8f6-cbf0-4e02-9a46-021d7f579bd0"
      },
      "source": [
        "#info: data will be overwritten on workflow feed- Ajay confirmed\n",
        "#looks like to read multiple pages one url is not enough\n",
        "!pip install xmltodict\n",
        "from datetime import date, datetime\n",
        "\n",
        "\n",
        "#links for 6 workflow feeds\n",
        "url_mShift = \"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=moU39Gbxtz9IhQO0gUy@EQAKbJcR374vb@IVb6kWwH0=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\"# 3 record\n",
        "url_mJob=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=GIcqmjbvPvCFX3QNIsJbTNa99MyIUuvAFUyKPTBcs9g=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" #has zero records\n",
        "url_mStation=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=GN3jGNVF03thDKOMppdZf/hjLH5vss2SgBlEkNaZvtE=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" #20 records\n",
        "url_mZone=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=LYZEOIUPmsEILn4DoGwhlGw0VaYZ6Yh8@bEKrGOlN6A=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" # 2 records\n",
        "url_mLine=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=XWPuVgYIhUVEZXRsr6gAFq2BPeTCdlLJxRBpvg07WLM=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\" # 1 record\n",
        "url_mAsset=\"https://helio-ent-ice.c2m.net/Ice.svc/GetData?apikey=CSWQpToX4KLCwODDd3QCmBzak8/DYJ&feedID=/y0R6s3pWwReO8a/3ef9tmtO8RAT/U/AKFfmPAD3egA=&parameterType=LISTDATA&filtervalue=2000&filtertype=totalnoofrecords&startrecord=1\"\n",
        "\n",
        "url={'asset': url_mAsset, 'shift': url_mShift , 'job': url_mJob, 'station': url_mStation, 'zone': url_mZone, 'line': url_mLine}\n",
        "\n",
        "keys_to_extract= { 'asset' : [\"linelink\", \"zonelink\", \"stationlink\",\"assetname\", \"industry\",\"typeofasset\",\"modelnumber\",\"assetmanufacturer\",\"plancycletime\"] ,\n",
        "                  'station' : ['fmsstationname', 'fmsstationlinelink', 'fmsstationzonelink','fmsstationplannedmnt', 'fmsstationplannedcyctim', 'fmsstationjobsplanned', 'fmsstationtimetoent', 'fmsstationtimetopalm'],\n",
        "                  'zone' : ['fmszonename', 'fmszonelinelinking', 'fmszoneplannedmnt', 'fmszoneplannedcyctim', 'fmszonejobsplanned'],\n",
        "                  'shift' : ['fmsschedulename', 'fmsschedulelinelink', 'fmsschedulestarttime', 'fmsscheduleendtime','fmsschedulebreakstart','fmsschedulebreakend','fmsschedulelunchstart','fmsschedulelunchend','fmsscheduledaysnew'],\n",
        "                  'line' : ['fmslinelinename', 'fmslineplannedcycletime', 'fmslinejobsplanned', 'fmslineplannedmaintenac'],\n",
        "                  'job' : ['fmsjobname', 'fmsjoblinelink', 'fmsjobsshiftlink', 'fmsjobsstyle' ]}\n",
        "\n",
        "\n",
        "keys_to_convert={ 'asset' : {'linelink':'line', 'zonelink':'zone', 'stationlink':'station','assetname':'asset', 'industry':'industry','typeofasset':'type','modelnumber':'model_number','assetmanufacturer':'manufacturer','plancycletime':'planned_cycle_time' },\n",
        "                 \n",
        "\n",
        "                  'station' : {'fmsstationname':'station', 'fmsstationlinelink':'line', 'fmsstationzonelink':'zone','fmsstationplannedmnt':'next_maintenance', \n",
        "                               'fmsstationplannedcyctim':'planned_cycle_time', 'fmsstationjobsplanned':'planned_jobs', 'fmsstationtimetoent':'planned_op_time_to_enter', 'fmsstationtimetopalm':'planned_op_time_to_palm'},\n",
        "                 \n",
        "                  'zone' : {'fmszonename':'zone', 'fmszonelinelinking':'line', 'fmszoneplannedmnt':'next_maintenance', 'fmszoneplannedcyctim':'planned_cycle_time', 'fmszonejobsplanned':'planned_jobs'},\n",
        "                 \n",
        "                  'shift' : {'fmsschedulename':'shift', 'fmsschedulelinelink':'line',  'fmsschedulestarttime':'shift_start', 'fmsscheduleendtime':'shift_end','fmsschedulebreakstart':'break_start',\n",
        "                             'fmsschedulebreakend':'break_end','fmsschedulelunchstart':'lunch_start','fmsschedulelunchend':'lunch_end','fmsscheduledaysnew':'days_active'},\n",
        "                 \n",
        "\n",
        "                  'line' : {'fmslinelinename':'line', 'fmslineplannedcycletime':'planned_cycle_time', 'fmslinejobsplanned':'planned_jobs', 'fmslineplannedmaintenac':'next_maintenance'},\n",
        "                 \n",
        "\n",
        "                  'job' : {'fmsjobname':'job', 'fmsjoblinelink':'line', 'fmsjobsshiftlink':'shift', 'fmsjobsstyle':'style'}}\n",
        "                 \n",
        "\n",
        "def convert_keys(a_subset,keys_to_extract_test,create_key,level):\n",
        "  new_keys=keys_to_convert[level]#new_keys is a dictionary with old_key as key and new_key as value\n",
        "  #print('new',new_keys)\n",
        "  #change the key names of the a_subset as suggested in keys_to_convert \n",
        "  a_subset=dict([(new_keys.get(k), v) for k, v in a_subset.items()])\n",
        "  #print(a_subset)\n",
        "  return a_subset\n",
        "  \n",
        "def remove_redundant(a_subset,create_key,rid):\n",
        "  a_subset_new=a_subset.copy()\n",
        "  if rid==1:\n",
        "    key_to_remove_list=create_key[0:-1]#make a list without the last key since last key is the name\n",
        "    [a_subset_new.pop(key) for key in key_to_remove_list ]#redundant removed\n",
        "  return a_subset_new\n",
        "\n",
        "\n",
        "def fix_datetime(a_subset_new):\n",
        "  \n",
        "  date_str=a_subset_new['next_maintenance']\n",
        "  format_str = '%m/%d/%Y' # The format\n",
        "  datetime_obj = datetime.strptime(date_str, format_str)\n",
        "  #print(datetime_obj.date())\n",
        "  \n",
        "  a_subset_new['next_maintenance']= datetime_obj\n",
        "  return a_subset_new\n",
        "\n",
        "def make_shift_tuple(a_subset_new):\n",
        "    #keys to drop after tuples are made\n",
        "    key_to_remove_listy=['shift_start','shift_end','break_start','break_end','lunch_start','lunch_end']\n",
        "    format_str='%Y-%m-%d %H:%M %p'\n",
        "    str1='%Y-%m-%d %H:%M %S'\n",
        "    str2='%Y-%m-%d %I:%M %S %p'\n",
        "    for ky in key_to_remove_listy:\n",
        "        #time_str=a_subset_new[ky]#+str(datetime.date(datetime.now()))\n",
        "        time_str=str(datetime.date(datetime.now()))+' ' +a_subset_new[ky]\n",
        "        \n",
        "        #a_subset_new[ky] = datetime.strptime(time_str, format_str)\n",
        "        a_subset_new[ky] = datetime.strptime(time_str, format_str).strftime(str2)\n",
        "        \n",
        "    #make tuple of schedule\n",
        "    a_subset_new['shift_schedule']=(a_subset_new['shift_start'],a_subset_new['shift_end'])\n",
        "    print(a_subset_new['shift_schedule'][0])\n",
        "\n",
        "    #make tuple of break\n",
        "    a_subset_new['break']=(a_subset_new['break_start'],a_subset_new['break_end'])\n",
        "\n",
        "    #make tuple of lunch\n",
        "    a_subset_new['lunch']=(a_subset_new['lunch_start'],a_subset_new['lunch_end'])\n",
        "\n",
        "    #drop keys\n",
        "    [a_subset_new.pop(key) for key in key_to_remove_listy ]#redundant removed\n",
        "\n",
        "    return a_subset_new\n",
        "\n",
        "\n",
        "\n",
        "def replace_url(i,url_test):#don't need this\n",
        "  page_number=url_test[-10:].split('=')[1]\n",
        "  replace_this_str=\"startrecord=\"+page_number\n",
        "  by_this_str=\"startrecord=\"+str(i)\n",
        "  url_test=url_test.replace(replace_this_str,by_this_str)\n",
        "  \n",
        "  return url_test\n",
        "\n",
        "#test replace_url\n",
        "'''\n",
        "url['asset']=replace_url(20, url['asset'])\n",
        "url['asset']=replace_url(3, url['asset'])\n",
        "for i in range(leng_asset):#how to get to next page\n",
        "  url_a=replace_url(i,url_a)#replace the url with new page \n",
        "  response = requests.get(url_a)#get xml tree of assets\n",
        "\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (0.12.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nurl['asset']=replace_url(20, url['asset'])\\nurl['asset']=replace_url(3, url['asset'])\\nfor i in range(leng_asset):#how to get to next page\\n  url_a=replace_url(i,url_a)#replace the url with new page \\n  response = requests.get(url_a)#get xml tree of assets\\n\\n#\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcBf76tkc1SJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14ecabeb-a408-4e42-a202-40500d6afb4a"
      },
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import math\n",
        "import requests\n",
        "import xmltodict\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "from datetime import date, datetime\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "rid=1#remove redundant keys\n",
        "\n",
        "def get_all(url_level,keys_to_extract_test,level,create_key,dicty):\n",
        "  response = requests.get(url_level)#(url['asset'])#,headers=headers\n",
        "  xml=response.text\n",
        "  workflow_dict=xmltodict.parse(xml)\n",
        "  new_keys=keys_to_convert[level]\n",
        "  create_key = [new_keys[x] for x in create_key]#convert the key using new keys defined in keys_to_convert\n",
        "\n",
        "  for key, value in workflow_dict.items():#looks like 1 key 1 value\n",
        "    #print(key)#prints root\n",
        "\n",
        "    for key2, value2 in value.items():\n",
        "      #print(key2)#prints response\n",
        "      dic_outer=json.loads(json.dumps(value2))\n",
        "      fetched_records=dic_outer['@fetchedrecords']\n",
        "      total_records=dic_outer['@totalrecords']\n",
        "      pages=math.ceil(int(total_records)/int(fetched_records))\n",
        "\n",
        "\n",
        "      dataset_value=dic_outer['NewDataSet']\n",
        "      total_dics=len(dataset_value['Table1'])#dataset_value['Table1'] ===> it's a list\n",
        "      print('total_records',total_dics)\n",
        "\n",
        "      for i in range(total_dics):#total_dics == total_records\n",
        "\n",
        "        dict_i=dataset_value['Table1'][i] #type(dataset_value['Table1'][0])====>it's a dict\n",
        "        #print(dict_i)\n",
        "\n",
        "        a_subset = {keyu: dict_i[keyu] for keyu in keys_to_extract_test} #extract necessary key from asset dictionary, keys_to_extract_asset\n",
        "        a_subset = dict((k, str(v).lower()) for k, v in a_subset .items()) #values to lower case\n",
        "        a_subset = convert_keys(a_subset,keys_to_extract_test, create_key, level)\n",
        "\n",
        "\n",
        "        #a_subset=convert_keys(a_subset,keys_to_extract_test,level)#change the key names\n",
        "        if level=='line':\n",
        "          a_subset=fix_datetime(a_subset)   \n",
        "          dicty[a_subset[create_key[0]]]=a_subset\n",
        "        \n",
        "        if level=='zone':\n",
        "          a_subset_new=remove_redundant(a_subset,create_key,rid)\n",
        "          a_subset_new=fix_datetime(a_subset_new)                    \n",
        "          if 'zones' not in dicty[a_subset[create_key[0]]]:\n",
        "            dicty[a_subset[create_key[0]]]['zones']={a_subset[create_key[1]]:a_subset_new}\n",
        "          else:\n",
        "            dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]=a_subset_new\n",
        "\n",
        "\n",
        "        if level=='shift':\n",
        "          a_subset[create_key[1]]= a_subset[create_key[1]].replace(\" \",\"_\")#remove space from shift: shift 1==> shift_1\n",
        "          a_subset=make_shift_tuple(a_subset)\n",
        "          a_subset_new=remove_redundant(a_subset,create_key,rid)\n",
        "          \n",
        "          if 'shifts' not in dicty[a_subset[create_key[0]]]:\n",
        "            dicty[a_subset[create_key[0]]]['shifts']={a_subset[create_key[1]]:a_subset_new}\n",
        "          else:\n",
        "            dicty[a_subset[create_key[0]]]['shifts'][a_subset[create_key[1]]]=a_subset_new\n",
        "           \n",
        "\n",
        "        if level=='job':\n",
        "          a_subset[create_key[1]]= a_subset[create_key[1]].replace(\" \",\"_\")#remove space from shift: shift 1==> shift_1\n",
        "          a_subset_new=remove_redundant(a_subset,create_key,rid)\n",
        "          if 'jobs' not in dicty[a_subset[create_key[0]]]['shifts'][a_subset[create_key[1]]]:\n",
        "            dicty[a_subset[create_key[0]]]['shifts'][a_subset[create_key[1]]]['jobs']={a_subset[create_key[2]]:a_subset_new}\n",
        "\n",
        "          else:\n",
        "            dicty[a_subset[create_key[0]]]['shifts'][a_subset[create_key[1]]]['jobs'][a_subset[create_key[2]]]=a_subset_new\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "        if level=='station':\n",
        "          a_subset_new=remove_redundant(a_subset,create_key,rid)\n",
        "          a_subset_new=fix_datetime(a_subset_new)   \n",
        "          if 'stations' not in dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]:\n",
        "            dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]['stations']={a_subset[create_key[2]]:a_subset_new}\n",
        "\n",
        "          else:\n",
        "            dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]['stations'][a_subset[create_key[2]]]=a_subset_new\n",
        "\n",
        "\n",
        "\n",
        "        if level=='asset':\n",
        "          a_subset_new=remove_redundant(a_subset,create_key,rid)\n",
        "          if 'assets' not in dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]['stations'][a_subset[create_key[2]]]:\n",
        "            dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]['stations'][a_subset[create_key[2]]]['assets']={a_subset[create_key[3]]:a_subset_new}\n",
        "          else:\n",
        "            dicty[a_subset[create_key[0]]]['zones'][a_subset[create_key[1]]]['stations'][a_subset[create_key[2]]]['assets'][a_subset[create_key[3]]]=a_subset_new\n",
        "          \n",
        "\n",
        "      \n",
        "      return dicty\n",
        "\n",
        "      \n",
        "level='line'\n",
        "line_key=['fmslinelinename']\n",
        "dicty={}\n",
        "keys_extract=keys_to_extract[level]\n",
        "dicty=get_all(url[level],keys_extract,level,line_key,dicty)\n",
        "#print(dicty)\n",
        "\n",
        "\n",
        "\n",
        "level='shift'\n",
        "shift_key=['fmsschedulelinelink','fmsschedulename' ]\n",
        "keys_extract=keys_to_extract[level]\n",
        "dicty=get_all(url[level],keys_extract,level,shift_key,dicty)\n",
        "#print(dicty)\n",
        "\n",
        "\n",
        "level='job'\n",
        "job_key=['fmsjoblinelink', 'fmsjobsshiftlink', 'fmsjobname']#line+shift+job\n",
        "keys_extract=keys_to_extract[level]\n",
        "dicty=get_all(url[level],keys_extract,level,job_key,dicty)#change key name\n",
        "#print(dicty)\n",
        "\n",
        "\n",
        "\n",
        "level='zone'\n",
        "zone_key=['fmszonelinelinking','fmszonename']\n",
        "keys_extract=keys_to_extract[level]\n",
        "dicty=get_all(url[level],keys_extract,level,zone_key,dicty)\n",
        "#print(dicty)\n",
        "\n",
        "\n",
        "level='station'\n",
        "station_key=['fmsstationlinelink', 'fmsstationzonelink', 'fmsstationname']\n",
        "keys_extract=keys_to_extract[level]\n",
        "dicty=get_all(url[level],keys_extract,level,station_key,dicty)\n",
        "#print(dicty)\n",
        "\n",
        "level='asset'\n",
        "asset_key=['linelink', 'zonelink', 'stationlink','assetname']\n",
        "keys_extract=keys_to_extract[level]\n",
        "dicty=get_all(url[level],keys_extract,level,asset_key,dicty)\n",
        "#print(dicty)\n",
        "#'''\n",
        "\n",
        "print (json.dumps(dicty, indent=1, default=str))\n",
        "#'''\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_records 2\n",
            "total_records 6\n",
            "helo done\n",
            "helo done\n",
            "helo done\n",
            "helo done\n",
            "helo done\n",
            "helo done\n",
            "total_records 2\n",
            "total_records 4\n",
            "total_records 40\n",
            "total_records 47\n",
            "{\n",
            " \"rw44\": {\n",
            "  \"line\": \"rw44\",\n",
            "  \"planned_cycle_time\": \"300\",\n",
            "  \"planned_jobs\": \"10\",\n",
            "  \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "  \"shifts\": {\n",
            "   \"shift_1\": {\n",
            "    \"shift\": \"shift_1\",\n",
            "    \"days_active\": \"monday!tuesday!wednesday!thursday!friday\",\n",
            "    \"shift_schedule\": [\n",
            "     \"1900-01-01 12:00:00\",\n",
            "     \"1900-01-01 08:00:00\"\n",
            "    ],\n",
            "    \"break\": [\n",
            "     \"1900-01-01 02:00:00\",\n",
            "     \"1900-01-01 02:15:00\"\n",
            "    ],\n",
            "    \"lunch\": [\n",
            "     \"1900-01-01 04:00:00\",\n",
            "     \"1900-01-01 05:00:00\"\n",
            "    ],\n",
            "    \"jobs\": {\n",
            "     \"gm001\": {\n",
            "      \"job\": \"gm001\",\n",
            "      \"style\": \"none\"\n",
            "     }\n",
            "    }\n",
            "   },\n",
            "   \"shift_2\": {\n",
            "    \"shift\": \"shift_2\",\n",
            "    \"days_active\": \"monday!tuesday!wednesday!thursday!friday\",\n",
            "    \"shift_schedule\": [\n",
            "     \"1900-01-01 08:00:00\",\n",
            "     \"1900-01-01 04:00:00\"\n",
            "    ],\n",
            "    \"break\": [\n",
            "     \"1900-01-01 10:00:00\",\n",
            "     \"1900-01-01 10:30:00\"\n",
            "    ],\n",
            "    \"lunch\": [\n",
            "     \"1900-01-01 12:00:00\",\n",
            "     \"1900-01-01 01:00:00\"\n",
            "    ]\n",
            "   },\n",
            "   \"shift_3\": {\n",
            "    \"shift\": \"shift_3\",\n",
            "    \"days_active\": \"monday!tuesday!wednesday!thursday!friday\",\n",
            "    \"shift_schedule\": [\n",
            "     \"1900-01-01 04:00:00\",\n",
            "     \"1900-01-01 12:00:00\"\n",
            "    ],\n",
            "    \"break\": [\n",
            "     \"1900-01-01 06:00:00\",\n",
            "     \"1900-01-01 06:15:00\"\n",
            "    ],\n",
            "    \"lunch\": [\n",
            "     \"1900-01-01 08:00:00\",\n",
            "     \"1900-01-01 09:00:00\"\n",
            "    ]\n",
            "   }\n",
            "  },\n",
            "  \"zones\": {\n",
            "   \"zone01\": {\n",
            "    \"zone\": \"zone01\",\n",
            "    \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "    \"planned_cycle_time\": \"124\",\n",
            "    \"planned_jobs\": \"100\",\n",
            "    \"stations\": {\n",
            "     \"st020\": {\n",
            "      \"station\": \"st020\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"020sr1\": {\n",
            "        \"asset\": \"020sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210  f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st030\": {\n",
            "      \"station\": \"st030\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"030sr1\": {\n",
            "        \"asset\": \"030sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st035\": {\n",
            "      \"station\": \"st035\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"035mr1\": {\n",
            "        \"asset\": \"035mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st040\": {\n",
            "      \"station\": \"st040\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"040ar1\": {\n",
            "        \"asset\": \"040ar1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"040ar2\": {\n",
            "        \"asset\": \"040ar2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st045\": {\n",
            "      \"station\": \"st045\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"045mr1\": {\n",
            "        \"asset\": \"045mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st050\": {\n",
            "      \"station\": \"st050\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st010\": {\n",
            "      \"station\": \"st010\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"010sr1\": {\n",
            "        \"asset\": \"010sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     }\n",
            "    }\n",
            "   },\n",
            "   \"zone02\": {\n",
            "    \"zone\": \"zone02\",\n",
            "    \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "    \"planned_cycle_time\": \"124\",\n",
            "    \"planned_jobs\": \"100\",\n",
            "    \"stations\": {\n",
            "     \"st200\": {\n",
            "      \"station\": \"st200\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"200mr2\": {\n",
            "        \"asset\": \"200mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"200sr1\": {\n",
            "        \"asset\": \"200sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st300\": {\n",
            "      \"station\": \"st300\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"300sr1\": {\n",
            "        \"asset\": \"300sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"300mr2\": {\n",
            "        \"asset\": \"300mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st350\": {\n",
            "      \"station\": \"st350\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st400\": {\n",
            "      \"station\": \"st400\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"400sr1\": {\n",
            "        \"asset\": \"400sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"400mr2\": {\n",
            "        \"asset\": \"400mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st500\": {\n",
            "      \"station\": \"st500\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"500sr1\": {\n",
            "        \"asset\": \"500sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"500mr2\": {\n",
            "        \"asset\": \"500mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st520\": {\n",
            "      \"station\": \"st520\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"520mr1\": {\n",
            "        \"asset\": \"520mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st540\": {\n",
            "      \"station\": \"st540\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"540sr1\": {\n",
            "        \"asset\": \"540sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"540mr1\": {\n",
            "        \"asset\": \"540mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st560\": {\n",
            "      \"station\": \"st560\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st600\": {\n",
            "      \"station\": \"st600\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st060\": {\n",
            "      \"station\": \"st060\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"060ar1\": {\n",
            "        \"asset\": \"060ar1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"060ar2\": {\n",
            "        \"asset\": \"060ar2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st080\": {\n",
            "      \"station\": \"st080\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"080ar1\": {\n",
            "        \"asset\": \"080ar1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st090\": {\n",
            "      \"station\": \"st090\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"10000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st100\": {\n",
            "      \"station\": \"st100\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"10\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"100sr1\": {\n",
            "        \"asset\": \"100sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       },\n",
            "       \"100mr2\": {\n",
            "        \"asset\": \"100mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"5\"\n",
            "       }\n",
            "      }\n",
            "     }\n",
            "    }\n",
            "   }\n",
            "  }\n",
            " },\n",
            " \"rw43\": {\n",
            "  \"line\": \"rw43\",\n",
            "  \"planned_cycle_time\": \"248\",\n",
            "  \"planned_jobs\": \"10\",\n",
            "  \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "  \"shifts\": {\n",
            "   \"shift_1\": {\n",
            "    \"shift\": \"shift_1\",\n",
            "    \"days_active\": \"monday!tuesday!wednesday!thursday!friday\",\n",
            "    \"shift_schedule\": [\n",
            "     \"1900-01-01 12:00:00\",\n",
            "     \"1900-01-01 08:00:00\"\n",
            "    ],\n",
            "    \"break\": [\n",
            "     \"1900-01-01 02:00:00\",\n",
            "     \"1900-01-01 02:15:00\"\n",
            "    ],\n",
            "    \"lunch\": [\n",
            "     \"1900-01-01 04:00:00\",\n",
            "     \"1900-01-01 05:00:00\"\n",
            "    ],\n",
            "    \"jobs\": {\n",
            "     \"ford 001\": {\n",
            "      \"job\": \"ford 001\",\n",
            "      \"style\": \"none\"\n",
            "     }\n",
            "    }\n",
            "   },\n",
            "   \"shift_2\": {\n",
            "    \"shift\": \"shift_2\",\n",
            "    \"days_active\": \"monday!tuesday!wednesday!thursday!friday\",\n",
            "    \"shift_schedule\": [\n",
            "     \"1900-01-01 08:00:00\",\n",
            "     \"1900-01-01 04:00:00\"\n",
            "    ],\n",
            "    \"break\": [\n",
            "     \"1900-01-01 10:00:00\",\n",
            "     \"1900-01-01 10:15:00\"\n",
            "    ],\n",
            "    \"lunch\": [\n",
            "     \"1900-01-01 12:00:00\",\n",
            "     \"1900-01-01 01:00:00\"\n",
            "    ]\n",
            "   },\n",
            "   \"shift_3\": {\n",
            "    \"shift\": \"shift_3\",\n",
            "    \"days_active\": \"monday!tuesday!wednesday!thursday!friday\",\n",
            "    \"shift_schedule\": [\n",
            "     \"1900-01-01 04:00:00\",\n",
            "     \"1900-01-01 12:00:00\"\n",
            "    ],\n",
            "    \"break\": [\n",
            "     \"1900-01-01 06:00:00\",\n",
            "     \"1900-01-01 06:15:00\"\n",
            "    ],\n",
            "    \"lunch\": [\n",
            "     \"1900-01-01 08:00:00\",\n",
            "     \"1900-01-01 09:00:00\"\n",
            "    ]\n",
            "   }\n",
            "  },\n",
            "  \"zones\": {\n",
            "   \"zone01\": {\n",
            "    \"zone\": \"zone01\",\n",
            "    \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "    \"planned_cycle_time\": \"200\",\n",
            "    \"planned_jobs\": \"1000\",\n",
            "    \"stations\": {\n",
            "     \"st010\": {\n",
            "      \"station\": \"st010\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"010sr1\": {\n",
            "        \"asset\": \"010sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 1000mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"240\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st020\": {\n",
            "      \"station\": \"st020\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"020sr1\": {\n",
            "        \"asset\": \"020sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f- 800 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"220\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st030\": {\n",
            "      \"station\": \"st030\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"030sr1\": {\n",
            "        \"asset\": \"030sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f 1000mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"180\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st035\": {\n",
            "      \"station\": \"st035\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"035mr1\": {\n",
            "        \"asset\": \"035mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 30mm plate\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st040\": {\n",
            "      \"station\": \"st040\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"040ar1\": {\n",
            "        \"asset\": \"040ar1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"120ic - 800mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"040ar2\": {\n",
            "        \"asset\": \"040ar2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"120ic - 400mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st045\": {\n",
            "      \"station\": \"st045\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"045mr1\": {\n",
            "        \"asset\": \"045mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210f - 30mm plate\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st050\": {\n",
            "      \"station\": \"st050\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     }\n",
            "    }\n",
            "   },\n",
            "   \"zone02\": {\n",
            "    \"zone\": \"zone02\",\n",
            "    \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "    \"planned_cycle_time\": \"100\",\n",
            "    \"planned_jobs\": \"1000\",\n",
            "    \"stations\": {\n",
            "     \"st350\": {\n",
            "      \"station\": \"st350\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st400\": {\n",
            "      \"station\": \"st400\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"400sr1\": {\n",
            "        \"asset\": \"400sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 800mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"400mr2\": {\n",
            "        \"asset\": \"400mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 1000 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st500\": {\n",
            "      \"station\": \"st500\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"500sr1\": {\n",
            "        \"asset\": \"500sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 1000mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"500mr2\": {\n",
            "        \"asset\": \"500mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 600 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st520\": {\n",
            "      \"station\": \"st520\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"520mr1\": {\n",
            "        \"asset\": \"520mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 30 mm plate\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st540\": {\n",
            "      \"station\": \"st540\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"540mr1\": {\n",
            "        \"asset\": \"540mr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 1000mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"540sr1\": {\n",
            "        \"asset\": \"540sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"none\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st560\": {\n",
            "      \"station\": \"st560\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st600\": {\n",
            "      \"station\": \"st600\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\"\n",
            "     },\n",
            "     \"st060\": {\n",
            "      \"station\": \"st060\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"060ar1\": {\n",
            "        \"asset\": \"060ar1\",\n",
            "        \"industry\": \"none\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"120ic - 28mm plate\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"060ar2\": {\n",
            "        \"asset\": \"060ar2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"120ic - 28mm plate\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st080\": {\n",
            "      \"station\": \"st080\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"080ar1\": {\n",
            "        \"asset\": \"080ar1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"120ic - 28mm  plate\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st090\": {\n",
            "      \"station\": \"st090\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"090sr1\": {\n",
            "        \"asset\": \"090sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 600 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st100\": {\n",
            "      \"station\": \"st100\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"100sr1\": {\n",
            "        \"asset\": \"100sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 600 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"100mr2\": {\n",
            "        \"asset\": \"100mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 1000 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st200\": {\n",
            "      \"station\": \"st200\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"200sr1\": {\n",
            "        \"asset\": \"200sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f -  800 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"200mr2\": {\n",
            "        \"asset\": \"200mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 1000mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     },\n",
            "     \"st300\": {\n",
            "      \"station\": \"st300\",\n",
            "      \"next_maintenance\": \"2020-07-31 00:00:00\",\n",
            "      \"planned_cycle_time\": \"100\",\n",
            "      \"planned_jobs\": \"1000\",\n",
            "      \"planned_op_time_to_enter\": \"20\",\n",
            "      \"planned_op_time_to_palm\": \"20\",\n",
            "      \"assets\": {\n",
            "       \"300sr1\": {\n",
            "        \"asset\": \"300sr1\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 600 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       },\n",
            "       \"300mr2\": {\n",
            "        \"asset\": \"300mr2\",\n",
            "        \"industry\": \"manufacturing\",\n",
            "        \"type\": \"robotic arm\",\n",
            "        \"model_number\": \"210 f - 600 mm riser\",\n",
            "        \"manufacturer\": \"fanuc\",\n",
            "        \"planned_cycle_time\": \"100\"\n",
            "       }\n",
            "      }\n",
            "     }\n",
            "    }\n",
            "   }\n",
            "  }\n",
            " }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubBpyG9o7ZW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#redis host\n",
        "redis_host=\"192.168.2.11\"\n",
        "redis_port = 6379\n",
        "redis_password = \"\"\n",
        "r=redis.Redis(host=\"192.168.2.11\", port=6379, db=0)\n",
        "\n",
        "\n",
        "#write workflowfeeds on redis\n",
        "r_val=json.dumps(dicty)\n",
        "r.set('workflow_lines',r_val)#UNCOMMENT\n",
        "r.get('workflow_lines')\n",
        "\n",
        "#new link: https://colab.research.google.com/drive/1NkMcpPuWcTBJ1_69DQPtOaO17dVIuANW#scrollTo=mK68snSLJ01C "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncWXCm_J-ApZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "f55cb3cd-4481-477a-ea03-dc99a4779ae3"
      },
      "source": [
        "#without dic\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import math\n",
        "import requests\n",
        "import xmltodict\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "def get_all(url_level,keys_to_extract_test,level):\n",
        "  response = requests.get(url_level)#(url['asset'])#,headers=headers\n",
        "  xml=response.text\n",
        "  workflow_dict=xmltodict.parse(xml)\n",
        "\n",
        "  for key, value in workflow_dict.items():#looks like 1 key 1 value\n",
        "    #print(key)#prints root\n",
        "\n",
        "    for key2, value2 in value.items():\n",
        "      #print(key2)#prints response\n",
        "      dic_outer=json.loads(json.dumps(value2))\n",
        "      fetched_records=dic_outer['@fetchedrecords']\n",
        "      total_records=dic_outer['@totalrecords']\n",
        "      pages=math.ceil(int(total_records)/int(fetched_records))\n",
        "\n",
        "\n",
        "      dataset_value=dic_outer['NewDataSet']\n",
        "      total_dics=len(dataset_value['Table1'])#dataset_value['Table1'] ===> it's a list\n",
        "      print('total_records',total_dics)\n",
        "\n",
        "      for i in range(total_dics):#total_dics == total_records\n",
        "\n",
        "        dict_i=dataset_value['Table1'][i] #type(dataset_value['Table1'][0])====>it's a dict\n",
        "        #print(dict_i)\n",
        "\n",
        "        a_subset = {keyu: dict_i[keyu] for keyu in keys_to_extract_test} #extract necessary key from asset dictionary, keys_to_extract_asset\n",
        "\n",
        "\n",
        "        #a_subset=convert_keys(a_subset,keys_to_extract_test,level)#change the key names\n",
        "\n",
        "        #dicty[a_subset[create_key]]=a_subset\n",
        "        print(a_subset)\n",
        "      \n",
        "      #return dicty\n",
        "\n",
        "level='shift'\n",
        "keys_extract=keys_to_extract[level]\n",
        "get_all(url[level],keys_extract,level)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_records 6\n",
            "{'fmsschedulename': 'Shift 2', 'fmsschedulelinelink': 'RW43', 'fmsschedulestarttime': '08:00 Am', 'fmsscheduleendtime': '04:00 Pm', 'fmsschedulebreakstart': '10:00 Am', 'fmsschedulebreakend': '10:15 Am', 'fmsschedulelunchstart': '12:00 Pm', 'fmsschedulelunchend': '01:00 Pm', 'fmsscheduledaysnew': 'Monday!Tuesday!Wednesday!Thursday!Friday'}\n",
            "{'fmsschedulename': 'Shift 3', 'fmsschedulelinelink': 'RW43', 'fmsschedulestarttime': '04:00 Pm', 'fmsscheduleendtime': '12:00 Am', 'fmsschedulebreakstart': '06:00 Am', 'fmsschedulebreakend': '06:15 Am', 'fmsschedulelunchstart': '08:00 Pm', 'fmsschedulelunchend': '09:00 Pm', 'fmsscheduledaysnew': 'Monday!Tuesday!Wednesday!Thursday!Friday'}\n",
            "{'fmsschedulename': 'Shift 1', 'fmsschedulelinelink': 'RW44', 'fmsschedulestarttime': '12:00 Am', 'fmsscheduleendtime': '08:00 Am', 'fmsschedulebreakstart': '02:00 Am', 'fmsschedulebreakend': '02:15 Am', 'fmsschedulelunchstart': '04:00 Am', 'fmsschedulelunchend': '05:00 Am', 'fmsscheduledaysnew': 'Monday!Tuesday!Wednesday!Thursday!Friday'}\n",
            "{'fmsschedulename': 'Shift 2', 'fmsschedulelinelink': 'RW44', 'fmsschedulestarttime': '08:00 Am', 'fmsscheduleendtime': '04:00 Pm', 'fmsschedulebreakstart': '10:00 Am', 'fmsschedulebreakend': '10:30 Am', 'fmsschedulelunchstart': '12:00 Pm', 'fmsschedulelunchend': '01:00 Pm', 'fmsscheduledaysnew': 'Monday!Tuesday!Wednesday!Thursday!Friday'}\n",
            "{'fmsschedulename': 'Shift 3', 'fmsschedulelinelink': 'RW44', 'fmsschedulestarttime': '04:00 Pm', 'fmsscheduleendtime': '12:00 Am', 'fmsschedulebreakstart': '06:00 Pm', 'fmsschedulebreakend': '06:15 Pm', 'fmsschedulelunchstart': '08:00 Pm', 'fmsschedulelunchend': '09:00 Pm', 'fmsscheduledaysnew': 'Monday!Tuesday!Wednesday!Thursday!Friday'}\n",
            "{'fmsschedulename': 'Shift 1', 'fmsschedulelinelink': 'RW43', 'fmsschedulestarttime': '12:00 Am', 'fmsscheduleendtime': '08:00 Am', 'fmsschedulebreakstart': '02:00 Am', 'fmsschedulebreakend': '02:15 Am', 'fmsschedulelunchstart': '04:00 Am', 'fmsschedulelunchend': '05:00 Am', 'fmsscheduledaysnew': 'Monday!Tuesday!Wednesday!Thursday!Friday'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV5JGrpPchZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "72c2487d-c84d-4e6e-c2cf-b6217987bb15"
      },
      "source": [
        "#loop to make big dictionary\n",
        "\n",
        "level='line'\n",
        "keys_extract=keys_to_extract[level]\n",
        "get_all(url[level],keys_extract,level)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_records 2\n",
            "{'fmslinelinename': 'RW43', 'fmslineplannedcycletime': '248', 'fmslinejobsplanned': '10', 'fmslineselection': None, 'fmslineplannedmntnc': None, 'fmslinepdm': None, 'fmslineplannedmaintenac': '07/31/2020'}\n",
            "{'fmslinelinename': 'RW44', 'fmslineplannedcycletime': '300', 'fmslinejobsplanned': '10', 'fmslineselection': None, 'fmslineplannedmntnc': None, 'fmslinepdm': None, 'fmslineplannedmaintenac': '07/31/2020'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0DsiWJOY9-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d4f00e46-3c46-449b-b47e-190ae489b658"
      },
      "source": [
        "#a_subset['shift']= a_subset['shift'].replace(\" \",\"_\")\n",
        "'shift 1'.replace(\" \",\"_\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'shift_1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YSMm0PvBKSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9167f0b8-3e29-429e-bbc3-f20612df5ac3"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import xmltodict\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "response = requests.get(url['asset'])#,headers=headers\n",
        "xml=response.text\n",
        "my_dict=xmltodict.parse(xml)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for key,value in my_dict.items():\n",
        "  print(key)\n",
        "  for key2,value2 in value.items():\n",
        "    print(key2)\n",
        "    dic_outer=json.loads(json.dumps(value2))\n",
        "    print(dic_outer)\n",
        "    print(dic_outer['@fetchedrecords'])\n",
        "    print(dic_outer['@totalrecords'])\n",
        "\n",
        "    dataset_value=dic_outer['NewDataSet']\n",
        "    total_dics=len(dataset_value['Table1'])#dataset_value['Table1'] ===> it's a list\n",
        "    print('total_records',total_dics)\n",
        "    dict_i=dataset_value['Table1'][0] #type(dataset_value['Table1'][0])====>it's a dict\n",
        "    print(dict_i)\n",
        "    \n",
        "    keys_to_extract_asset = [\"assetname\", \"industry\",\"typeofasset\",\"modelnumber\",\"assetmanufacturer\",\"plancycletime\"]\n",
        "\n",
        "    a_subset = {keyu: dict_i[keyu] for keyu in keys_to_extract_asset} #extract necessary key from asset dictionary\n",
        "    print(a_subset)\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            "response\n",
            "{'@status': 'SUCCESS', '@startrecord': '1', '@fetchedrecords': '47', '@totalrecords': '47', 'NewDataSet': {'Table1': [{'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11897', 'assetid': '5JOK7', 'assetname': '300SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:14:20.000Z', 'ModifiedOn': '2020-06-30T23:14:20.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST300', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11898', 'assetid': '5SE9N', 'assetname': '300MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:15:22.000Z', 'ModifiedOn': '2020-06-30T23:15:22.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST300', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11899', 'assetid': '5RP1L', 'assetname': '400SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:16:20.000Z', 'ModifiedOn': '2020-06-30T23:16:20.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST400', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11900', 'assetid': '5PAQ1', 'assetname': '400MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:17:21.000Z', 'ModifiedOn': '2020-06-30T23:17:21.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST400', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11901', 'assetid': '5S6R9', 'assetname': '500SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:18:09.000Z', 'ModifiedOn': '2020-06-30T23:18:09.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST500', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11902', 'assetid': '5VLRS', 'assetname': '500MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:19:15.000Z', 'ModifiedOn': '2020-06-30T23:19:15.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST500', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11903', 'assetid': '5MSJD', 'assetname': '520MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:20:08.000Z', 'ModifiedOn': '2020-06-30T23:20:08.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST520', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11904', 'assetid': '5HJ2K', 'assetname': '540SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:21:02.000Z', 'ModifiedOn': '2020-06-30T23:21:02.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST540', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11905', 'assetid': '5POW6', 'assetname': '540MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:21:59.000Z', 'ModifiedOn': '2020-06-30T23:21:59.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST540', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11888', 'assetid': '5CS4M', 'assetname': '040AR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:03:23.000Z', 'ModifiedOn': '2020-06-30T23:03:23.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST040', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11889', 'assetid': '55K9P', 'assetname': '045MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:04:26.000Z', 'ModifiedOn': '2020-06-30T23:04:26.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST045', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11890', 'assetid': '53478', 'assetname': '060AR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:05:49.000Z', 'ModifiedOn': '2020-06-30T23:05:49.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST060', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11891', 'assetid': '5LU2Y', 'assetname': '060AR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:06:35.000Z', 'ModifiedOn': '2020-06-30T23:06:35.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST060', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11892', 'assetid': '5QXQC', 'assetname': '080AR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:07:37.000Z', 'ModifiedOn': '2020-06-30T23:07:37.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST080', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11893', 'assetid': '5TOX4', 'assetname': '100SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:08:54.000Z', 'ModifiedOn': '2020-06-30T23:08:54.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST100', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11894', 'assetid': '5HIUJ', 'assetname': '100MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:10:18.000Z', 'ModifiedOn': '2020-06-30T23:10:18.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST100', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11895', 'assetid': '5U9CW', 'assetname': '200SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:11:59.000Z', 'ModifiedOn': '2020-06-30T23:11:59.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST200', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.465Z', 'trnsctnid': '11896', 'assetid': '5FUVS', 'assetname': '200MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:13:07.000Z', 'ModifiedOn': '2020-06-30T23:13:07.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST200', 'zonelink': 'Zone02', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11853', 'assetid': '5S4F4', 'assetname': '520MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 30 MM Plate', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T15:03:54.000Z', 'ModifiedOn': '2020-06-24T15:31:22.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST520', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11854', 'assetid': '5YZQI', 'assetname': '540SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': None, 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T15:04:56.000Z', 'ModifiedOn': '2020-06-24T15:34:41.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST540', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11855', 'assetid': '5BNXO', 'assetname': '540MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 1000MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': '88:5f:97:97:c2:fc', 'CreatededOn': '2020-06-24T15:05:42.000Z', 'ModifiedOn': '2020-06-29T14:26:10.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST540', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11883', 'assetid': '57E2J', 'assetname': '010SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2019', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T22:52:50.000Z', 'ModifiedOn': '2020-06-30T22:52:50.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST010', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11884', 'assetid': '597DP', 'assetname': '020SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210  F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T22:54:10.000Z', 'ModifiedOn': '2020-06-30T22:54:10.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST020', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11885', 'assetid': '5OKR4', 'assetname': '030SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T22:55:34.000Z', 'ModifiedOn': '2020-06-30T22:55:34.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST030', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11886', 'assetid': '5ISGG', 'assetname': '035MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T22:57:28.000Z', 'ModifiedOn': '2020-06-30T22:57:28.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST035', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.464Z', 'trnsctnid': '11887', 'assetid': '59N2H', 'assetname': '040AR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:01:38.000Z', 'ModifiedOn': '2020-06-30T23:02:04.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST040', 'zonelink': 'Zone01', 'plancycletime': '5'}, {'c2mdatetime': '2020-07-02T17:35:33.463Z', 'trnsctnid': '11847', 'assetid': '566GZ', 'assetname': '300SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 600 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:51:09.000Z', 'ModifiedOn': '2020-06-24T15:26:55.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST300', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.463Z', 'trnsctnid': '11848', 'assetid': '5IPTF', 'assetname': '300MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 600 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:52:39.000Z', 'ModifiedOn': '2020-06-24T15:27:38.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST300', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.463Z', 'trnsctnid': '11849', 'assetid': '5TWX4', 'assetname': '400SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 800MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:53:38.000Z', 'ModifiedOn': '2020-06-24T15:28:31.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST400', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.463Z', 'trnsctnid': '11850', 'assetid': '5SQJT', 'assetname': '400MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 1000 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:58:24.000Z', 'ModifiedOn': '2020-06-24T15:29:33.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST400', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.463Z', 'trnsctnid': '11851', 'assetid': '5NP4M', 'assetname': '500SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 1000MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:59:35.000Z', 'ModifiedOn': '2020-06-24T15:30:11.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST500', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.463Z', 'trnsctnid': '11852', 'assetid': '5I7RV', 'assetname': '500MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 600 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T15:00:27.000Z', 'ModifiedOn': '2020-06-24T15:30:44.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST500', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11840', 'assetid': '5TAOF', 'assetname': '060AR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '120ic - 28MM Plate', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:43:00.000Z', 'ModifiedOn': '2020-06-24T15:18:55.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST060', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11841', 'assetid': '5HWGX', 'assetname': '080AR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '120ic - 28MM  Plate', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:44:02.000Z', 'ModifiedOn': '2020-06-24T15:19:50.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST080', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11842', 'assetid': '5WMVJ', 'assetname': '090SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 600 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:46:08.000Z', 'ModifiedOn': '2020-06-24T15:21:24.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST090', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11843', 'assetid': '5YXLM', 'assetname': '100SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 600 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:47:27.000Z', 'ModifiedOn': '2020-06-24T15:22:07.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST100', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11844', 'assetid': '5LMKD', 'assetname': '100MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 1000 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:48:24.000Z', 'ModifiedOn': '2020-06-24T15:24:56.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST100', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11845', 'assetid': '5HMZR', 'assetname': '200SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F -  800 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:49:38.000Z', 'ModifiedOn': '2020-06-24T15:24:28.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST200', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.462Z', 'trnsctnid': '11846', 'assetid': '52C8Q', 'assetname': '200MR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 1000MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:50:19.000Z', 'ModifiedOn': '2020-06-24T15:25:52.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST200', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.461Z', 'trnsctnid': '11835', 'assetid': '5QQ9F', 'assetname': '035MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 30MM Plate', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:36:28.000Z', 'ModifiedOn': '2020-06-24T15:12:51.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST035', 'zonelink': 'Zone01', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.461Z', 'trnsctnid': '11836', 'assetid': '5LFNP', 'assetname': '040AR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '120ic - 800MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:37:24.000Z', 'ModifiedOn': '2020-06-24T15:14:03.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST040', 'zonelink': 'Zone01', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.461Z', 'trnsctnid': '11837', 'assetid': '57IQA', 'assetname': '040AR2', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '120ic - 400MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:38:37.000Z', 'ModifiedOn': '2020-06-24T15:16:26.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST040', 'zonelink': 'Zone01', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.461Z', 'trnsctnid': '11838', 'assetid': '53JYO', 'assetname': '045MR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210F - 30MM Plate', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:39:43.000Z', 'ModifiedOn': '2020-06-24T15:16:08.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST045', 'zonelink': 'Zone01', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.461Z', 'trnsctnid': '11839', 'assetid': '5HGDF', 'assetname': '060AR1', 'industry': None, 'typeofasset': 'Robotic Arm', 'modelnumber': '120ic - 28MM Plate', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:40:39.000Z', 'ModifiedOn': '2020-06-24T15:18:07.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': None, 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST060', 'zonelink': 'Zone02', 'plancycletime': '100'}, {'c2mdatetime': '2020-07-02T17:35:33.460Z', 'trnsctnid': '11832', 'assetid': '54NM1', 'assetname': '010SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F - 1000MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:26:47.000Z', 'ModifiedOn': '2020-06-24T15:09:21.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST010', 'zonelink': 'Zone01', 'plancycletime': '240'}, {'c2mdatetime': '2020-07-02T17:35:33.460Z', 'trnsctnid': '11833', 'assetid': '5OZNX', 'assetname': '020SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F- 800 MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:29:59.000Z', 'ModifiedOn': '2020-06-24T15:10:13.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST020', 'zonelink': 'Zone01', 'plancycletime': '220'}, {'c2mdatetime': '2020-07-02T17:35:33.460Z', 'trnsctnid': '11834', 'assetid': '5FRGU', 'assetname': '030SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F 1000MM Riser', 'assetmanufacturer': 'Fanuc', 'assetyear': None, 'assetapplication': None, 'assetoperation': None, 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-24T14:34:54.000Z', 'ModifiedOn': '2020-06-24T15:11:46.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': None, 'linelink': 'RW43', 'stationlink': 'ST030', 'zonelink': 'Zone01', 'plancycletime': '180'}]}}\n",
            "47\n",
            "47\n",
            "total_records 47\n",
            "{'c2mdatetime': '2020-07-02T17:35:33.466Z', 'trnsctnid': '11897', 'assetid': '5JOK7', 'assetname': '300SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'assetyear': '2020', 'assetapplication': None, 'assetoperation': 'Automatic', 'Monitoringdeviceid': None, 'CreatededOn': '2020-06-30T23:14:20.000Z', 'ModifiedOn': '2020-06-30T23:14:20.000Z', 'StageName': 'Asset Status', 'StateName': 'Active', 'username': 'lmv_admin@yopmail.com', 'companyname': 'MagnaLMVCompany4', 'groupname': 'MagnaLMVCompany4', 'region': 'North', 'tco': '1000', 'linelink': 'RW44', 'stationlink': 'ST300', 'zonelink': 'Zone02', 'plancycletime': '5'}\n",
            "{'assetname': '300SR1', 'industry': 'Manufacturing', 'typeofasset': 'Robotic Arm', 'modelnumber': '210 F', 'assetmanufacturer': 'Fanuc', 'plancycletime': '5'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh5TVmsbYOe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e639d87c-5934-4be1-9d8d-0d5d712d5686"
      },
      "source": [
        "listy=['b','d']\n",
        "d={'a':'aa','b':'bb','c':'cc','d':'dd'}\n",
        "[d.pop(key) for key in listy ]\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 'aa', 'c': 'cc'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et_Q_z2qC9js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STore\n",
        "# HOW TO FETCH RECORD BY RECORD: IS IT POSSIBLE IN MY CASE?\n",
        "# https://stackoverflow.com/questions/45293458/how-to-read-the-next-page-on-api-using-python\n",
        "\n",
        "\n",
        "def get_records(response_text):\n",
        "    for node in response_text.iter():\n",
        "      if node.tag=='response':\n",
        "        print(node.attrib)\n",
        "        fetched_records=node.attrib['fetchedrecords']# node.attrib ==> dictionary of response tag in asset level\n",
        "        total_records=node.attrib['totalrecords']\n",
        "        #print(fetched_records)\n",
        "        break\n",
        "\n",
        "    leng=math.ceil(int(total_records)/int(fetched_records))\n",
        "    return leng, fetched_records, total_records\n",
        "\n",
        "\n",
        "response = requests.get(url['asset'])#,headers=headers\n",
        "response_text=ET.fromstring(response.text)#prints wordpad with xd \n",
        "leng_asset, fetched_records, total_records=get_records(response_text)\n",
        "print(fetched_records, total_records)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}